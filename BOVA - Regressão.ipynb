{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "342632b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing column provided to 'parse_dates': 'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 94>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     90\u001b[0m        pd\u001b[38;5;241m.\u001b[39mDataFrame([best_params])\u001b[38;5;241m.\u001b[39mto_excel(writer, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, sheet_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_params\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# =======================\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# 1) REGRESSÃO LINEAR (RIDGE)\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# =======================\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mcarregar_base\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m df_train, X, y \u001b[38;5;241m=\u001b[39m preparar_treino(df)\n\u001b[0;32m     96\u001b[0m ridge \u001b[38;5;241m=\u001b[39m Pipeline([(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m, StandardScaler()), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m, Ridge())])\n",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36mcarregar_base\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcarregar_base\u001b[39m():\n\u001b[1;32m---> 22\u001b[0m    df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINPUT_CSV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m    df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     24\u001b[0m    \u001b[38;5;28;01massert\u001b[39;00m pd\u001b[38;5;241m.\u001b[39misna(df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, TARGET]), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA última linha (dez/2023) deve ter close_plus1 em branco.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1235\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1232\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:152\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_usecols_names(\n\u001b[0;32m    147\u001b[0m             usecols,\n\u001b[0;32m    148\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m    149\u001b[0m         )\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[1;32m--> 152\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_parse_dates_presence\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_noconvert_columns()\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:228\u001b[0m, in \u001b[0;36mParserBase._validate_parse_dates_presence\u001b[1;34m(self, columns)\u001b[0m\n\u001b[0;32m    218\u001b[0m missing_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;28msorted\u001b[39m(\n\u001b[0;32m    220\u001b[0m         {\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    225\u001b[0m     )\n\u001b[0;32m    226\u001b[0m )\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_cols:\n\u001b[1;32m--> 228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    229\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing column provided to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparse_dates\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_cols\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    230\u001b[0m     )\n\u001b[0;32m    231\u001b[0m \u001b[38;5;66;03m# Convert positions to actual column names\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    233\u001b[0m     col \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns) \u001b[38;5;28;01melse\u001b[39;00m columns[col]\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cols_needed\n\u001b[0;32m    235\u001b[0m ]\n",
      "\u001b[1;31mValueError\u001b[0m: Missing column provided to 'parse_dates': 'date'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "# ===== Configurações gerais =====\n",
    "INPUT_CSV = r\"C:\\Users\\kinagaki\\OneDrive - Digicorner\\Desktop\\Trabalho de Conclusão de Curso - UFRJ.2025\\Correção\\versão atualizada\\TESTE BOVA 11\\bova11_ate_2023.csv\"   # seu arquivo\n",
    "OUTPUT_DIR = \"saidas_modelos\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "FEATS = ['ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel']  # sem macro\n",
    "TARGET = 'close_plus1'\n",
    "N_SPLITS = 5  # TimeSeriesSplit\n",
    "# ===== Funções utilitárias =====\n",
    "def roll_mean(a, n): return np.mean(a[-n:]) if len(a) >= n else np.nan\n",
    "def roll_std(a, n):  return np.std(a[-n:], ddof=1) if len(a) >= n else np.nan\n",
    "def carregar_base():\n",
    "   df = pd.read_csv(INPUT_CSV, parse_dates=['date'])\n",
    "   df = df.sort_values('date').reset_index(drop=True)\n",
    "   assert pd.isna(df.loc[len(df)-1, TARGET]), \"A última linha (dez/2023) deve ter close_plus1 em branco.\"\n",
    "   return df\n",
    "def preparar_treino(df):\n",
    "   df_train = df.dropna(subset=FEATS + [TARGET]).copy()\n",
    "   X = df_train[FEATS].values\n",
    "   y = df_train[TARGET].values\n",
    "   return df_train, X, y\n",
    "def avaliar_oof(model, X, y, scaler=False):\n",
    "   \"\"\"Avalia com TimeSeriesSplit e retorna métricas + previsões OOF.\"\"\"\n",
    "   tscv = TimeSeriesSplit(n_splits=N_SPLITS)\n",
    "   y_oof = np.empty_like(y, dtype=float); y_oof[:] = np.nan\n",
    "   for tr, te in tscv.split(X):\n",
    "       model.fit(X[tr], y[tr])\n",
    "       y_oof[te] = model.predict(X[te])\n",
    "   mae  = mean_absolute_error(y, y_oof)\n",
    "   rmse = mean_squared_error(y, y_oof, squared=False)\n",
    "   r2   = r2_score(y, y_oof)\n",
    "   return {'MAE': mae, 'RMSE': rmse, 'R2': r2}, y_oof\n",
    "def treinar_escolher(model, grid, X, y):\n",
    "   \"\"\"GridSearchCV com TimeSeriesSplit; retorna melhor estimador e params.\"\"\"\n",
    "   tscv = TimeSeriesSplit(n_splits=N_SPLITS)\n",
    "   g = GridSearchCV(model, grid, cv=tscv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "   g.fit(X, y)\n",
    "   best = g.best_estimator_\n",
    "   return best, g.best_params_\n",
    "def projetar_2024(model, df_hist):\n",
    "   \"\"\"\n",
    "   Projeção recursiva jan–dez/2024:\n",
    "   - usa apenas features internas\n",
    "   - recalcula MM/Vol/Momentum a cada mês com closes previstos\n",
    "   - volrel futuro: média dos últimos 3 observados\n",
    "   \"\"\"\n",
    "   df_work = df_hist[['date','close','ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel']].copy()\n",
    "   volrel_last3 = df_work['volrel'].tail(3).mean()\n",
    "   last_close = df_work['close'].iloc[-1]\n",
    "   rows = []\n",
    "   for i in range(12):\n",
    "       feats_now = df_work.iloc[-1][FEATS].to_dict()\n",
    "       feats_now['volrel'] = volrel_last3  # suposição p/ o mês seguinte\n",
    "       x = np.array([feats_now[f] for f in FEATS], dtype=float).reshape(1, -1)\n",
    "       pred_close_next = float(model.predict(x)[0])\n",
    "       next_date = df_work['date'].iloc[-1] + pd.offsets.MonthBegin(1)\n",
    "       ret_next = (pred_close_next / last_close) - 1.0\n",
    "       # anexa linha prevista\n",
    "       row = {'date': next_date,\n",
    "              'close': pred_close_next,\n",
    "              'ret_m': ret_next,\n",
    "              'volrel': volrel_last3}\n",
    "       df_work = pd.concat([df_work, pd.DataFrame([row])], ignore_index=True)\n",
    "       # recalcula features na última linha\n",
    "       closes = df_work['close'].values\n",
    "       rets   = df_work['ret_m'].values\n",
    "       df_work.loc[df_work.index[-1], 'mm3']  = roll_mean(closes, 3)\n",
    "       df_work.loc[df_work.index[-1], 'mm6']  = roll_mean(closes, 6)\n",
    "       df_work.loc[df_work.index[-1], 'mm12'] = roll_mean(closes, 12)\n",
    "       df_work.loc[df_work.index[-1], 'vol3'] = roll_std(rets, 3)\n",
    "       df_work.loc[df_work.index[-1], 'vol6'] = roll_std(rets, 6)\n",
    "       if len(closes) >= 4:\n",
    "           df_work.loc[df_work.index[-1], 'momentum3'] = (closes[-1]/closes[-4]) - 1\n",
    "       last_close = pred_close_next\n",
    "       rows.append({'date': next_date, 'close_pred': pred_close_next})\n",
    "   return pd.DataFrame(rows)\n",
    "def salvar_excel(caminho, previsoes_df, metricas, best_params):\n",
    "   with pd.ExcelWriter(caminho, engine='xlsxwriter') as writer:\n",
    "       previsoes_df.to_excel(writer, index=False, sheet_name='predicoes_2024')\n",
    "       pd.DataFrame([metricas]).to_excel(writer, index=False, sheet_name='metricas')\n",
    "       pd.DataFrame([best_params]).to_excel(writer, index=False, sheet_name='best_params')\n",
    "# =======================\n",
    "# 1) REGRESSÃO LINEAR (RIDGE)\n",
    "# =======================\n",
    "df = carregar_base()\n",
    "df_train, X, y = preparar_treino(df)\n",
    "ridge = Pipeline([('scaler', StandardScaler()), ('model', Ridge())])\n",
    "grid_ridge = {'model__alpha': [0.1, 0.5, 1.0, 2.0, 5.0]}\n",
    "best_ridge, bestp_ridge = treinar_escolher(ridge, grid_ridge, X, y)\n",
    "met_ridge, _ = avaliar_oof(best_ridge, X, y)\n",
    "pred_ridge = projetar_2024(best_ridge, df)\n",
    "salvar_excel(os.path.join(OUTPUT_DIR, 'bova11_pred_2024_ridge.xlsx'),\n",
    "            pred_ridge, met_ridge, bestp_ridge)\n",
    "print(\"Arquivo salvo:\", os.path.join(OUTPUT_DIR, 'bova11_pred_2024_ridge.xlsx'))\n",
    "# =======================\n",
    "# 2) ÁRVORE DE DECISÃO\n",
    "# =======================\n",
    "tree = DecisionTreeRegressor(random_state=42)\n",
    "grid_tree = {'max_depth': [4, 6, 8, 10],\n",
    "            'min_samples_leaf': [5, 10, 20]}\n",
    "best_tree, bestp_tree = treinar_escolher(tree, grid_tree, X, y)\n",
    "met_tree, _ = avaliar_oof(best_tree, X, y)\n",
    "pred_tree = projetar_2024(best_tree, df)\n",
    "salvar_excel(os.path.join(OUTPUT_DIR, 'bova11_pred_2024_tree.xlsx'),\n",
    "            pred_tree, met_tree, bestp_tree)\n",
    "print(\"Arquivo salvo:\", os.path.join(OUTPUT_DIR, 'bova11_pred_2024_tree.xlsx'))\n",
    "# =======================\n",
    "# 3) RANDOM FOREST\n",
    "# =======================\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "grid_rf = {'n_estimators': [300, 500],\n",
    "          'max_depth': [6, 8, 12],\n",
    "          'min_samples_leaf': [3, 5, 10],\n",
    "          'max_features': [0.6, 'sqrt']}\n",
    "best_rf, bestp_rf = treinar_escolher(rf, grid_rf, X, y)\n",
    "met_rf, _ = avaliar_oof(best_rf, X, y)\n",
    "pred_rf = projetar_2024(best_rf, df)\n",
    "salvar_excel(os.path.join(OUTPUT_DIR, 'bova11_pred_2024_rf.xlsx'),\n",
    "            pred_rf, met_rf, bestp_rf)\n",
    "print(\"Arquivo salvo:\", os.path.join(OUTPUT_DIR, 'bova11_pred_2024_rf.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "254fee19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date   close    ret_m       mm3       mm6      mm12    vol3    vol6  \\\n",
      "0  2020-01-01   108,9  -0,0209    108,16  104,3883   99,2958  0,0614  0,0614   \n",
      "1  2020-02-01   100,6  -0,0762    106,91  104,8867   100,025  0,0717  0,0717   \n",
      "2  2020-03-01   69,35  -0,3106     92,95     99,61   98,1533  0,1538  0,1611   \n",
      "3  2020-04-01   77,21   0,1133   82,3867   95,2733   96,8475  0,2124  0,1654   \n",
      "4  2020-05-01   84,15   0,0899   76,9033   91,9067   96,0608  0,2383   0,158   \n",
      "5  2020-06-01   91,62   0,0888   84,3267   88,6383   95,6033  0,0139  0,1608   \n",
      "6  2020-07-01   99,29   0,0837   91,6867   87,0367   95,7125  0,0033  0,1662   \n",
      "7  2020-08-01    95,7  -0,0362   95,5367     86,22   95,5533  0,0707  0,1634   \n",
      "8  2020-09-01   91,05  -0,0486   95,3467   89,8367   94,7233  0,0731  0,0712   \n",
      "9  2020-10-01   90,66  -0,0043     92,47   92,0783   93,6758  0,0229  0,0658   \n",
      "10 2020-11-01     105   0,1582     95,57   95,5533     93,73  0,1089  0,0823   \n",
      "11 2020-12-01  114,65   0,0919  103,4367   99,3917    94,015  0,0817  0,0827   \n",
      "12 2021-01-01  110,56  -0,0357    110,07    101,27   94,1533  0,0985  0,0846   \n",
      "13 2021-02-01  105,59   -0,045  110,2667  102,9183   94,5692  0,0765  0,0859   \n",
      "14 2021-03-01  112,02   0,0609    109,39  106,4133    98,125  0,0586    0,08   \n",
      "15 2021-04-01   114,4   0,0212    110,67    110,37  101,2242  0,0535  0,0779   \n",
      "16 2021-05-01  121,25   0,0599    115,89  113,0783  104,3158  0,0226  0,0558   \n",
      "17 2021-06-01  121,81   0,0046  119,1533  114,2717  106,8317  0,0284  0,0455   \n",
      "18 2021-07-01  117,11  -0,0386  120,0567  115,3633  108,3167  0,0494  0,0461   \n",
      "19 2021-08-01  114,08  -0,0259  117,6667  116,7783  109,8483  0,0222  0,0419   \n",
      "20 2021-09-01  106,49  -0,0665    112,56  115,8567   111,135  0,0208  0,0454   \n",
      "21 2021-10-01   99,68  -0,0639    106,75  113,4033  111,8867  0,0228  0,0478   \n",
      "22 2021-11-01   98,35  -0,0133  101,5067  109,5867  111,3325    0,03  0,0281   \n",
      "23 2021-12-01   100,8   0,0249     99,61   106,085  110,1783  0,0446  0,0343   \n",
      "24 2022-01-01  107,98   0,0712  102,3767  104,5633  109,9633  0,0424  0,0532   \n",
      "25 2022-02-01   108,9   0,0085  105,8933     103,7  110,2392  0,0325  0,0533   \n",
      "26 2022-03-01   115,6   0,0615  110,8267  105,2183  110,5375  0,0338    0,05   \n",
      "27 2022-04-01   103,4  -0,1055     109,3  105,8383  109,6208  0,0854   0,064   \n",
      "28 2022-05-01  107,18   0,0366  108,7267    107,31  108,4483  0,0901   0,064   \n",
      "29 2022-06-01      95  -0,1136    101,86  106,3433  106,2142  0,0845  0,0825   \n",
      "30 2022-07-01    99,3   0,0453  100,4933  104,8967    104,73  0,0893  0,0782   \n",
      "31 2022-08-01  105,83   0,0658  100,0433   104,385  104,0425  0,0982  0,0843   \n",
      "32 2022-09-01  106,46    0,006  103,8633  102,8617    104,04  0,0304  0,0788   \n",
      "33 2022-10-01  112,15   0,0534  108,1467    104,32  105,0792  0,0316  0,0664   \n",
      "34 2022-11-01  108,58  -0,0318  109,0633  104,5533  105,9317  0,0427   0,068   \n",
      "35 2022-12-01  105,95  -0,0242  108,8933  106,3783  106,3608  0,0472  0,0417   \n",
      "36 2023-01-01  109,84   0,0367  108,1233   108,135  106,5158  0,0376  0,0407   \n",
      "37 2023-02-01  101,15  -0,0791  105,6467   107,355    105,87  0,0579  0,0487   \n",
      "38 2023-03-01   98,49  -0,0263    103,16  106,0267  104,4442   0,058  0,0488   \n",
      "39 2023-04-01   100,9   0,0245    100,18  104,1517  104,2358  0,0518   0,042   \n",
      "40 2023-05-01  104,84    0,039    101,41  103,5283  104,0408  0,0343  0,0466   \n",
      "41 2023-06-01  114,17    0,089  106,6367  104,8983  105,6383  0,0338  0,0586   \n",
      "42 2023-07-01  117,95   0,0331    112,32    106,25  107,1925  0,0307  0,0583   \n",
      "43 2023-08-01  112,31  -0,0478    114,81    108,11  107,7325  0,0688  0,0491   \n",
      "44 2023-09-01  113,15   0,0075    114,47  110,5533    108,29  0,0414  0,0446   \n",
      "45 2023-10-01  109,62  -0,0312  111,6933  112,0067  108,0792  0,0284    0,05   \n",
      "46 2023-11-01  123,57   0,1273  115,4467  115,1283  109,3283  0,0826  0,0682   \n",
      "47 2023-12-01  130,39   0,0552  121,1933  117,8317   111,365  0,0793  0,0636   \n",
      "\n",
      "   momentum3  volrel selic_m   ipca_m close_plus1  \n",
      "0     0,0549  1,2997   0,045   0,0021       108,9  \n",
      "1    -0,0359  1,3491  0,0425   0,0025       100,6  \n",
      "2    -0,3765   4,086  0,0375   0,0007       69,35  \n",
      "3     -0,291  1,2272  0,0375  -0,0031       77,21  \n",
      "4    -0,1635  0,8369    0,03  -0,0038       84,15  \n",
      "5     0,3211   0,698  0,0225   0,0026       91,62  \n",
      "6      0,286  0,6773  0,0225   0,0036       99,29  \n",
      "7     0,1373  0,9108    0,02   0,0024        95,7  \n",
      "8    -0,0062  1,0265    0,02   0,0064       91,05  \n",
      "9    -0,0869  1,1338    0,02   0,0086       90,66  \n",
      "10    0,0972  1,0215    0,02   0,0089         105  \n",
      "11    0,2592   0,716    0,02   0,0135      114,65  \n",
      "12    0,2195  0,8119    0,02   0,0025      110,56  \n",
      "13    0,0056  0,9266    0,02   0,0086      105,59  \n",
      "14   -0,0229  1,4813  0,0275   0,0093      112,02  \n",
      "15    0,0347  0,7502  0,0275   0,0031       114,4  \n",
      "16    0,1483   0,688   0,035   0,0083      121,25  \n",
      "17    0,0874  0,6569  0,0425   0,0053      121,81  \n",
      "18    0,0237  0,8683  0,0425   0,0096      117,11  \n",
      "19   -0,0591  1,4022  0,0525   0,0087      114,08  \n",
      "20   -0,1258  1,6237  0,0625   0,0116      106,49  \n",
      "21   -0,1488  1,4061  0,0775   0,0125       99,68  \n",
      "22   -0,1379  1,0319  0,0775   0,0095       98,35  \n",
      "23   -0,0534  0,7633  0,0925   0,0073       100,8  \n",
      "24    0,0833   0,873  0,0925   0,0054      107,98  \n",
      "25    0,1073  0,7656  0,1075   0,0101       108,9  \n",
      "26    0,1468  1,0912  0,1175   0,0162       115,6  \n",
      "27   -0,0424  0,6216  0,1175   0,0106       103,4  \n",
      "28   -0,0158  1,2171  0,1275   0,0047      107,18  \n",
      "29   -0,1782  1,2465  0,1325   0,0067          95  \n",
      "30   -0,0397  0,9732  0,1325  -0,0068        99,3  \n",
      "31   -0,0126   1,012  0,1375  -0,0036      105,83  \n",
      "32    0,1206  0,8261  0,1375  -0,0029      106,46  \n",
      "33    0,1294  1,0948  0,1375   0,0059      112,15  \n",
      "34     0,026  1,3275  0,1375   0,0041      108,58  \n",
      "35   -0,0048  1,0847  0,1375   0,0062      105,95  \n",
      "36   -0,0206  0,7495  0,1375   0,0053      109,84  \n",
      "37   -0,0684  0,7272  0,1375   0,0084      101,15  \n",
      "38   -0,0704  1,2349  0,1375   0,0071       98,49  \n",
      "39   -0,0814  0,8271  0,1375   0,0061       100,9  \n",
      "40    0,0365  1,2846  0,1375   0,0023      104,84  \n",
      "41    0,1592  0,8928  0,1375  -0,0008      114,17  \n",
      "42     0,169  0,8842  0,1375   0,0012      117,95  \n",
      "43    0,0713   0,903  0,1325   0,0023      112,31  \n",
      "44   -0,0089  0,7038  0,1275   0,0026      113,15  \n",
      "45   -0,0706  0,7208  0,1275   0,0024      109,62  \n",
      "46    0,1003  1,0294  0,1225   0,0028      123,57  \n",
      "47    0,1524  0,7966  0,1175   0,0056         NaN  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 40>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m    best_ridge\u001b[38;5;241m.\u001b[39mfit(X[tr], y[tr])\n\u001b[0;32m     39\u001b[0m    y_oof[te] \u001b[38;5;241m=\u001b[39m best_ridge\u001b[38;5;241m.\u001b[39mpredict(X[te])\n\u001b[1;32m---> 40\u001b[0m mae  \u001b[38;5;241m=\u001b[39m \u001b[43mmean_absolute_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_oof\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m rmse \u001b[38;5;241m=\u001b[39m mean_squared_error(y, y_oof, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     42\u001b[0m r2   \u001b[38;5;241m=\u001b[39m r2_score(y, y_oof)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py:277\u001b[0m, in \u001b[0;36mmean_absolute_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;124;03m\"\"\"Mean absolute error regression loss.\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \n\u001b[0;32m    224\u001b[0m \u001b[38;5;124;03mRead more in the :ref:`User Guide <mean_absolute_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03m0.85...\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    274\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred, sample_weight, multioutput)\n\u001b[0;32m    276\u001b[0m _, y_true, y_pred, sample_weight, multioutput \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 277\u001b[0m     \u001b[43m_check_reg_targets_with_floating_dtype\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    280\u001b[0m )\n\u001b[0;32m    282\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    284\u001b[0m output_errors \u001b[38;5;241m=\u001b[39m _average(\n\u001b[0;32m    285\u001b[0m     xp\u001b[38;5;241m.\u001b[39mabs(y_pred \u001b[38;5;241m-\u001b[39m y_true), weights\u001b[38;5;241m=\u001b[39msample_weight, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp\n\u001b[0;32m    286\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py:198\u001b[0m, in \u001b[0;36m_check_reg_targets_with_floating_dtype\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, xp)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;124;03m\"\"\"Ensures that y_true, y_pred, and sample_weight correspond to the same\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;124;03mregression task.\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;124;03m    correct keyword.\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    196\u001b[0m dtype_name \u001b[38;5;241m=\u001b[39m _find_matching_floating_dtype(y_true, y_pred, sample_weight, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m--> 198\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;66;03m# _check_reg_targets does not accept sample_weight as input.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;66;03m# Convert sample_weight's data type separately to match dtype_name.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\metrics\\_regression.py:106\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[0;32m    104\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m    105\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m--> 106\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    109\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mreshape(y_true, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:1107\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[1;32m-> 1107\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1116\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:120\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:169\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    168\u001b[0m     )\n\u001b[1;32m--> 169\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:\\Users\\kinagaki\\OneDrive - Digicorner\\Desktop\\Trabalho de Conclusão de Curso - UFRJ.2025\\Correção\\versão atualizada\\TESTE BOVA 11\\bova11_ate_2023.csv\", sep=\";\")   # ou o caminho completo\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df = df.sort_values(\"date\")\n",
    "print(df.head(49))\n",
    "# === 0) PADRONIZAÇÃO NUMÉRICA (se seu CSV veio com vírgula decimal) ===\n",
    "# Se suas colunas já estão numéricas, este bloco não fará nada de errado.\n",
    "num_cols = ['close','ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel','close_plus1']\n",
    "for c in num_cols:\n",
    "   if c in df.columns:\n",
    "       df[c] = (df[c].astype(str).str.replace('.', '', regex=False)  # remove separador de milhar, se houver\n",
    "                          .str.replace(',', '.', regex=False))       # vírgula -> ponto\n",
    "       df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "# Conferir última linha do alvo (DEVE estar vazia para prever jan/2024)\n",
    "assert pd.isna(df.loc[len(df)-1, 'close_plus1']), \"A última linha (dez/2023) deve estar vazia em close_plus1.\"\n",
    "# === 1) TREINO (Ridge) com validação temporal ===\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "FEATS = ['ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel']\n",
    "TARGET = 'close_plus1'\n",
    "# tira linhas iniciais com janelas incompletas e a última (alvo vazio)\n",
    "train = df.dropna(subset=FEATS + [TARGET]).copy()\n",
    "X = train[FEATS].values\n",
    "y = train[TARGET].values\n",
    "ridge = Pipeline([('scaler', StandardScaler()), ('m', Ridge())])\n",
    "grid  = {'m__alpha': [0.1, 0.5, 1.0, 2.0, 5.0]}\n",
    "tscv  = TimeSeriesSplit(n_splits=5)\n",
    "g = GridSearchCV(ridge, grid, cv=tscv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "g.fit(X, y)\n",
    "best_ridge = g.best_estimator_\n",
    "# OOF metrics\n",
    "y_oof = np.empty_like(y, dtype=float); y_oof[:] = np.nan\n",
    "for tr, te in tscv.split(X):\n",
    "   best_ridge.fit(X[tr], y[tr])\n",
    "   y_oof[te] = best_ridge.predict(X[te])\n",
    "mae  = mean_absolute_error(y, y_oof)\n",
    "rmse = mean_squared_error(y, y_oof, squared=False)\n",
    "r2   = r2_score(y, y_oof)\n",
    "print(f\"Ridge  | MAE={mae:.3f}  RMSE={rmse:.3f}  R²={r2:.3f}  best={g.best_params_}\")\n",
    "# === 2) PROJEÇÃO RECURSIVA (JAN–DEZ/2024) ===\n",
    "def roll_mean(a, n): return np.mean(a[-n:]) if len(a)>=n else np.nan\n",
    "def roll_std(a, n):  return np.std(a[-n:], ddof=1) if len(a)>=n else np.nan\n",
    "work = df[['date','close','ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel']].copy()\n",
    "volrel_last3 = work['volrel'].tail(3).mean()\n",
    "last_close    = work['close'].iloc[-1]\n",
    "rows = []\n",
    "for i in range(12):\n",
    "   # features do mês t (última linha disponível) para prever t+1\n",
    "   feats_now = work.iloc[-1][FEATS].to_dict()\n",
    "   feats_now['volrel'] = volrel_last3  # suposição para o próximo mês\n",
    "   x = np.array([feats_now[f] for f in FEATS], dtype=float).reshape(1, -1)\n",
    "   pred_close_next = float(best_ridge.predict(x)[0])\n",
    "   next_date = work['date'].iloc[-1] + pd.offsets.MonthBegin(1)\n",
    "   ret_next  = (pred_close_next / last_close) - 1.0\n",
    "   # anexa linha prevista\n",
    "   work = pd.concat([work, pd.DataFrame([{\n",
    "       'date': next_date, 'close': pred_close_next, 'ret_m': ret_next, 'volrel': volrel_last3\n",
    "   }])], ignore_index=True)\n",
    "   # recalcula features na última linha\n",
    "   closes = work['close'].values\n",
    "   rets   = work['ret_m'].values\n",
    "   work.loc[work.index[-1], 'mm3']  = roll_mean(closes, 3)\n",
    "   work.loc[work.index[-1], 'mm6']  = roll_mean(closes, 6)\n",
    "   work.loc[work.index[-1], 'mm12'] = roll_mean(closes,12)\n",
    "   work.loc[work.index[-1], 'vol3'] = roll_std(rets, 3)\n",
    "   work.loc[work.index[-1], 'vol6'] = roll_std(rets, 6)\n",
    "   if len(closes) >= 4:\n",
    "       work.loc[work.index[-1], 'momentum3'] = (closes[-1]/closes[-4]) - 1\n",
    "   last_close = pred_close_next\n",
    "   rows.append({'date': next_date, 'close_pred': pred_close_next})\n",
    "pred_ridge = pd.DataFrame(rows)\n",
    "print(pred_ridge)\n",
    "# === 3) SALVAR EM EXCEL ===\n",
    "with pd.ExcelWriter('bova11_pred_2024_ridge.xlsx', engine='xlsxwriter') as w:\n",
    "   pred_ridge.to_excel(w, index=False, sheet_name='predicoes_2024')\n",
    "   pd.DataFrame([{'MAE':mae, 'RMSE':rmse, 'R2':r2, **g.best_params_}]).to_excel(w, index=False, sheet_name='metricas')\n",
    "print(\"Arquivo gerado: bova11_pred_2024_ridge.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f08ebe6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN por coluna:\n",
      " ret_m          0\n",
      "mm3            0\n",
      "mm6            0\n",
      "mm12           0\n",
      "vol3           0\n",
      "vol6           0\n",
      "momentum3      0\n",
      "volrel         0\n",
      "close_plus1    1\n",
      "dtype: int64\n",
      "Linhas com NaN nas features/target:\n",
      "         date   close   ret_m       mm3       mm6     mm12    vol3    vol6  \\\n",
      "47 2023-12-01  130.39  0.0552  121.1933  117.8317  111.365  0.0793  0.0636   \n",
      "\n",
      "    momentum3  volrel selic_m  ipca_m  close_plus1  \n",
      "47     0.1524  0.7966  0,1175  0,0056          NaN  \n"
     ]
    }
   ],
   "source": [
    "print(\"NaN por coluna:\\n\", df[FEATS + [TARGET]].isna().sum())\n",
    "print(\"Linhas com NaN nas features/target:\")\n",
    "print(df[df[FEATS + [TARGET]].isna().any(1)].tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4805a3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date   close    ret_m       mm3       mm6      mm12    vol3    vol6  \\\n",
      "0  2020-01-01   108,9  -0,0209    108,16  104,3883   99,2958  0,0614  0,0614   \n",
      "1  2020-02-01   100,6  -0,0762    106,91  104,8867   100,025  0,0717  0,0717   \n",
      "2  2020-03-01   69,35  -0,3106     92,95     99,61   98,1533  0,1538  0,1611   \n",
      "3  2020-04-01   77,21   0,1133   82,3867   95,2733   96,8475  0,2124  0,1654   \n",
      "4  2020-05-01   84,15   0,0899   76,9033   91,9067   96,0608  0,2383   0,158   \n",
      "5  2020-06-01   91,62   0,0888   84,3267   88,6383   95,6033  0,0139  0,1608   \n",
      "6  2020-07-01   99,29   0,0837   91,6867   87,0367   95,7125  0,0033  0,1662   \n",
      "7  2020-08-01    95,7  -0,0362   95,5367     86,22   95,5533  0,0707  0,1634   \n",
      "8  2020-09-01   91,05  -0,0486   95,3467   89,8367   94,7233  0,0731  0,0712   \n",
      "9  2020-10-01   90,66  -0,0043     92,47   92,0783   93,6758  0,0229  0,0658   \n",
      "10 2020-11-01     105   0,1582     95,57   95,5533     93,73  0,1089  0,0823   \n",
      "11 2020-12-01  114,65   0,0919  103,4367   99,3917    94,015  0,0817  0,0827   \n",
      "12 2021-01-01  110,56  -0,0357    110,07    101,27   94,1533  0,0985  0,0846   \n",
      "13 2021-02-01  105,59   -0,045  110,2667  102,9183   94,5692  0,0765  0,0859   \n",
      "14 2021-03-01  112,02   0,0609    109,39  106,4133    98,125  0,0586    0,08   \n",
      "15 2021-04-01   114,4   0,0212    110,67    110,37  101,2242  0,0535  0,0779   \n",
      "16 2021-05-01  121,25   0,0599    115,89  113,0783  104,3158  0,0226  0,0558   \n",
      "17 2021-06-01  121,81   0,0046  119,1533  114,2717  106,8317  0,0284  0,0455   \n",
      "18 2021-07-01  117,11  -0,0386  120,0567  115,3633  108,3167  0,0494  0,0461   \n",
      "19 2021-08-01  114,08  -0,0259  117,6667  116,7783  109,8483  0,0222  0,0419   \n",
      "20 2021-09-01  106,49  -0,0665    112,56  115,8567   111,135  0,0208  0,0454   \n",
      "21 2021-10-01   99,68  -0,0639    106,75  113,4033  111,8867  0,0228  0,0478   \n",
      "22 2021-11-01   98,35  -0,0133  101,5067  109,5867  111,3325    0,03  0,0281   \n",
      "23 2021-12-01   100,8   0,0249     99,61   106,085  110,1783  0,0446  0,0343   \n",
      "24 2022-01-01  107,98   0,0712  102,3767  104,5633  109,9633  0,0424  0,0532   \n",
      "25 2022-02-01   108,9   0,0085  105,8933     103,7  110,2392  0,0325  0,0533   \n",
      "26 2022-03-01   115,6   0,0615  110,8267  105,2183  110,5375  0,0338    0,05   \n",
      "27 2022-04-01   103,4  -0,1055     109,3  105,8383  109,6208  0,0854   0,064   \n",
      "28 2022-05-01  107,18   0,0366  108,7267    107,31  108,4483  0,0901   0,064   \n",
      "29 2022-06-01      95  -0,1136    101,86  106,3433  106,2142  0,0845  0,0825   \n",
      "30 2022-07-01    99,3   0,0453  100,4933  104,8967    104,73  0,0893  0,0782   \n",
      "31 2022-08-01  105,83   0,0658  100,0433   104,385  104,0425  0,0982  0,0843   \n",
      "32 2022-09-01  106,46    0,006  103,8633  102,8617    104,04  0,0304  0,0788   \n",
      "33 2022-10-01  112,15   0,0534  108,1467    104,32  105,0792  0,0316  0,0664   \n",
      "34 2022-11-01  108,58  -0,0318  109,0633  104,5533  105,9317  0,0427   0,068   \n",
      "35 2022-12-01  105,95  -0,0242  108,8933  106,3783  106,3608  0,0472  0,0417   \n",
      "36 2023-01-01  109,84   0,0367  108,1233   108,135  106,5158  0,0376  0,0407   \n",
      "37 2023-02-01  101,15  -0,0791  105,6467   107,355    105,87  0,0579  0,0487   \n",
      "38 2023-03-01   98,49  -0,0263    103,16  106,0267  104,4442   0,058  0,0488   \n",
      "39 2023-04-01   100,9   0,0245    100,18  104,1517  104,2358  0,0518   0,042   \n",
      "40 2023-05-01  104,84    0,039    101,41  103,5283  104,0408  0,0343  0,0466   \n",
      "41 2023-06-01  114,17    0,089  106,6367  104,8983  105,6383  0,0338  0,0586   \n",
      "42 2023-07-01  117,95   0,0331    112,32    106,25  107,1925  0,0307  0,0583   \n",
      "43 2023-08-01  112,31  -0,0478    114,81    108,11  107,7325  0,0688  0,0491   \n",
      "44 2023-09-01  113,15   0,0075    114,47  110,5533    108,29  0,0414  0,0446   \n",
      "45 2023-10-01  109,62  -0,0312  111,6933  112,0067  108,0792  0,0284    0,05   \n",
      "46 2023-11-01  123,57   0,1273  115,4467  115,1283  109,3283  0,0826  0,0682   \n",
      "47 2023-12-01  130,39   0,0552  121,1933  117,8317   111,365  0,0793  0,0636   \n",
      "\n",
      "   momentum3  volrel selic_m   ipca_m close_plus1  \n",
      "0     0,0549  1,2997   0,045   0,0021       108,9  \n",
      "1    -0,0359  1,3491  0,0425   0,0025       100,6  \n",
      "2    -0,3765   4,086  0,0375   0,0007       69,35  \n",
      "3     -0,291  1,2272  0,0375  -0,0031       77,21  \n",
      "4    -0,1635  0,8369    0,03  -0,0038       84,15  \n",
      "5     0,3211   0,698  0,0225   0,0026       91,62  \n",
      "6      0,286  0,6773  0,0225   0,0036       99,29  \n",
      "7     0,1373  0,9108    0,02   0,0024        95,7  \n",
      "8    -0,0062  1,0265    0,02   0,0064       91,05  \n",
      "9    -0,0869  1,1338    0,02   0,0086       90,66  \n",
      "10    0,0972  1,0215    0,02   0,0089         105  \n",
      "11    0,2592   0,716    0,02   0,0135      114,65  \n",
      "12    0,2195  0,8119    0,02   0,0025      110,56  \n",
      "13    0,0056  0,9266    0,02   0,0086      105,59  \n",
      "14   -0,0229  1,4813  0,0275   0,0093      112,02  \n",
      "15    0,0347  0,7502  0,0275   0,0031       114,4  \n",
      "16    0,1483   0,688   0,035   0,0083      121,25  \n",
      "17    0,0874  0,6569  0,0425   0,0053      121,81  \n",
      "18    0,0237  0,8683  0,0425   0,0096      117,11  \n",
      "19   -0,0591  1,4022  0,0525   0,0087      114,08  \n",
      "20   -0,1258  1,6237  0,0625   0,0116      106,49  \n",
      "21   -0,1488  1,4061  0,0775   0,0125       99,68  \n",
      "22   -0,1379  1,0319  0,0775   0,0095       98,35  \n",
      "23   -0,0534  0,7633  0,0925   0,0073       100,8  \n",
      "24    0,0833   0,873  0,0925   0,0054      107,98  \n",
      "25    0,1073  0,7656  0,1075   0,0101       108,9  \n",
      "26    0,1468  1,0912  0,1175   0,0162       115,6  \n",
      "27   -0,0424  0,6216  0,1175   0,0106       103,4  \n",
      "28   -0,0158  1,2171  0,1275   0,0047      107,18  \n",
      "29   -0,1782  1,2465  0,1325   0,0067          95  \n",
      "30   -0,0397  0,9732  0,1325  -0,0068        99,3  \n",
      "31   -0,0126   1,012  0,1375  -0,0036      105,83  \n",
      "32    0,1206  0,8261  0,1375  -0,0029      106,46  \n",
      "33    0,1294  1,0948  0,1375   0,0059      112,15  \n",
      "34     0,026  1,3275  0,1375   0,0041      108,58  \n",
      "35   -0,0048  1,0847  0,1375   0,0062      105,95  \n",
      "36   -0,0206  0,7495  0,1375   0,0053      109,84  \n",
      "37   -0,0684  0,7272  0,1375   0,0084      101,15  \n",
      "38   -0,0704  1,2349  0,1375   0,0071       98,49  \n",
      "39   -0,0814  0,8271  0,1375   0,0061       100,9  \n",
      "40    0,0365  1,2846  0,1375   0,0023      104,84  \n",
      "41    0,1592  0,8928  0,1375  -0,0008      114,17  \n",
      "42     0,169  0,8842  0,1375   0,0012      117,95  \n",
      "43    0,0713   0,903  0,1325   0,0023      112,31  \n",
      "44   -0,0089  0,7038  0,1275   0,0026      113,15  \n",
      "45   -0,0706  0,7208  0,1275   0,0024      109,62  \n",
      "46    0,1003  1,0294  0,1225   0,0028      123,57  \n",
      "47    0,1524  0,7966  0,1175   0,0056         NaN  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot have number of folds=6 greater than the number of samples=0.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 26>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m tscv  \u001b[38;5;241m=\u001b[39m TimeSeriesSplit(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     25\u001b[0m g \u001b[38;5;241m=\u001b[39m GridSearchCV(ridge, grid, cv\u001b[38;5;241m=\u001b[39mtscv, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_absolute_error\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m best_ridge \u001b[38;5;241m=\u001b[39m g\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# 3) OOF com máscara (evita erro por NaN)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1020\u001b[0m     )\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1570\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1571\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:982\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    967\u001b[0m         )\n\u001b[0;32m    968\u001b[0m     )\n\u001b[0;32m    970\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    971\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    972\u001b[0m         clone(base_estimator),\n\u001b[0;32m    973\u001b[0m         X,\n\u001b[0;32m    974\u001b[0m         y,\n\u001b[0;32m    975\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    976\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    977\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    978\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    979\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    980\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    981\u001b[0m     )\n\u001b[1;32m--> 982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m \u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    986\u001b[0m )\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_split.py:1276\u001b[0m, in \u001b[0;36mTimeSeriesSplit._split\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1274\u001b[0m \u001b[38;5;66;03m# Make sure we have enough samples for the given split parameters\u001b[39;00m\n\u001b[0;32m   1275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_folds \u001b[38;5;241m>\u001b[39m n_samples:\n\u001b[1;32m-> 1276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot have number of folds=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_folds\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m greater\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1278\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m than the number of samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1279\u001b[0m     )\n\u001b[0;32m   1280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m-\u001b[39m gap \u001b[38;5;241m-\u001b[39m (test_size \u001b[38;5;241m*\u001b[39m n_splits) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1282\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToo many splits=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_splits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for number of samples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1283\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with test_size=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and gap=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgap\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1284\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot have number of folds=6 greater than the number of samples=0."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:\\Users\\kinagaki\\OneDrive - Digicorner\\Desktop\\Trabalho de Conclusão de Curso - UFRJ.2025\\Correção\\versão atualizada\\TESTE BOVA 11\\bova11_ate_2023.csv\", sep=\";\")   # ou o caminho completo\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "df = df.sort_values(\"date\")\n",
    "print(df.head(49))\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "FEATS = ['ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel']\n",
    "TARGET = 'close_plus1'\n",
    "# 0) Garante numérico (se já estiver, não muda nada)\n",
    "for c in ['close'] + FEATS + [TARGET]:\n",
    "   df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "# 1) Treino: remove linhas sem janelas completas e a última (TARGET vazio)\n",
    "train = df.dropna(subset=FEATS + [TARGET]).copy()\n",
    "X = train[FEATS].values\n",
    "y = train[TARGET].values\n",
    "# 2) Modelo + busca de alpha\n",
    "ridge = Pipeline([('scaler', StandardScaler()), ('m', Ridge())])\n",
    "grid  = {'m__alpha': [0.1, 0.5, 1.0, 2.0, 5.0]}\n",
    "tscv  = TimeSeriesSplit(n_splits=5)\n",
    "g = GridSearchCV(ridge, grid, cv=tscv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "g.fit(X, y)\n",
    "best_ridge = g.best_estimator_\n",
    "# 3) OOF com máscara (evita erro por NaN)\n",
    "y_oof = np.full_like(y, np.nan, dtype=float)\n",
    "for tr, te in tscv.split(X):\n",
    "   best_ridge.fit(X[tr], y[tr])\n",
    "   y_oof[te] = best_ridge.predict(X[te])\n",
    "mask = ~np.isnan(y_oof)\n",
    "mae  = mean_absolute_error(y[mask], y_oof[mask])\n",
    "rmse = mean_squared_error(y[mask], y_oof[mask], squared=False)\n",
    "r2   = r2_score(y[mask], y_oof[mask])\n",
    "print(f\"Ridge  | MAE={mae:.3f}  RMSE={rmse:.3f}  R²={r2:.3f}  best={g.best_params_}\")\n",
    "# 4) Projeção recursiva JAN–DEZ/2024 (sem macro)\n",
    "def roll_mean(a,n): return np.mean(a[-n:]) if len(a)>=n else np.nan\n",
    "def roll_std(a,n):  return np.std(a[-n:], ddof=1) if len(a)>=n else np.nan\n",
    "work = df[['date','close','ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel']].copy()\n",
    "volrel_last3 = work['volrel'].tail(3).mean()\n",
    "last_close   = work['close'].iloc[-1]\n",
    "rows = []\n",
    "for _ in range(12):\n",
    "   feats_now = work.iloc[-1][FEATS].to_dict()\n",
    "   feats_now['volrel'] = volrel_last3  # suposição para o mês seguinte\n",
    "   x = np.array([feats_now[f] for f in FEATS], dtype=float).reshape(1, -1)\n",
    "   pred_close_next = float(best_ridge.predict(x)[0])\n",
    "   next_date = work['date'].iloc[-1] + pd.offsets.MonthBegin(1)\n",
    "   ret_next  = (pred_close_next / last_close) - 1.0\n",
    "   # anexa linha prevista\n",
    "   work = pd.concat([work, pd.DataFrame([{\n",
    "       'date': next_date, 'close': pred_close_next, 'ret_m': ret_next, 'volrel': volrel_last3\n",
    "   }])], ignore_index=True)\n",
    "   # recalcula features na última linha\n",
    "   closes = work['close'].values\n",
    "   rets   = work['ret_m'].values\n",
    "   work.loc[work.index[-1], 'mm3']  = roll_mean(closes, 3)\n",
    "   work.loc[work.index[-1], 'mm6']  = roll_mean(closes, 6)\n",
    "   work.loc[work.index[-1], 'mm12'] = roll_mean(closes,12)\n",
    "   work.loc[work.index[-1], 'vol3'] = roll_std(rets, 3)\n",
    "   work.loc[work.index[-1], 'vol6'] = roll_std(rets, 6)\n",
    "   if len(closes) >= 4:\n",
    "       work.loc[work.index[-1], 'momentum3'] = (closes[-1]/closes[-4]) - 1\n",
    "   last_close = pred_close_next\n",
    "   rows.append({'date': next_date, 'close_pred': pred_close_next})\n",
    "pred_ridge = pd.DataFrame(rows)\n",
    "# 5) Salvar em Excel\n",
    "with pd.ExcelWriter('bova11_pred_2024_ridge.xlsx', engine='xlsxwriter') as w:\n",
    "   pred_ridge.to_excel(w, index=False, sheet_name='predicoes_2024')\n",
    "   pd.DataFrame([{'MAE':mae, 'RMSE':rmse, 'R2':r2, **g.best_params_}]).to_excel(w, index=False, sheet_name='metricas')\n",
    "print(\"Arquivo gerado: bova11_pred_2024_ridge.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e6ac279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de linhas no df: 48\n",
      "Total de linhas após dropna: 0\n",
      "ret_m          48\n",
      "mm3            48\n",
      "mm6            48\n",
      "mm12           48\n",
      "vol3           48\n",
      "vol6           48\n",
      "momentum3      48\n",
      "volrel         48\n",
      "close_plus1    46\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Total de linhas no df:\", len(df))\n",
    "print(\"Total de linhas após dropna:\", len(df.dropna(subset=FEATS + [TARGET])))\n",
    "print(df[FEATS + [TARGET]].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee43cdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dtypes:\n",
      " close          float64\n",
      "ret_m          float64\n",
      "mm3            float64\n",
      "mm6            float64\n",
      "mm12           float64\n",
      "vol3           float64\n",
      "vol6           float64\n",
      "momentum3      float64\n",
      "volrel         float64\n",
      "close_plus1    float64\n",
      "dtype: object\n",
      "\n",
      "NaN por coluna:\n",
      " close          0\n",
      "ret_m          0\n",
      "mm3            0\n",
      "mm6            0\n",
      "mm12           0\n",
      "vol3           0\n",
      "vol6           0\n",
      "momentum3      0\n",
      "volrel         0\n",
      "close_plus1    1\n",
      "dtype: int64\n",
      "\n",
      "Linhas totais: 48  | Linhas após dropna: 47\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "got an unexpected keyword argument 'squared'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 70>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     68\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mnp\u001b[38;5;241m.\u001b[39misnan(y_oof)\n\u001b[0;32m     69\u001b[0m mae  \u001b[38;5;241m=\u001b[39m mean_absolute_error(y[mask], y_oof[mask])\n\u001b[1;32m---> 70\u001b[0m rmse \u001b[38;5;241m=\u001b[39m \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_oof\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m r2   \u001b[38;5;241m=\u001b[39m r2_score(y[mask], y_oof[mask])\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRidge | MAE=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmae\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  RMSE=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmse\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  R²=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr2\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  best=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mg\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\_param_validation.py:194\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    191\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n\u001b[1;32m--> 194\u001b[0m params \u001b[38;5;241m=\u001b[39m func_sig\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    195\u001b[0m params\u001b[38;5;241m.\u001b[39mapply_defaults()\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# ignore self/cls and positional/keyword markers\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\inspect.py:3045\u001b[0m, in \u001b[0;36mSignature.bind\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3040\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   3041\u001b[0m     \u001b[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[0;32m   3042\u001b[0m \u001b[38;5;124;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[0;32m   3043\u001b[0m \u001b[38;5;124;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[0;32m   3044\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3045\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\inspect.py:3034\u001b[0m, in \u001b[0;36mSignature._bind\u001b[1;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[0;32m   3032\u001b[0m         arguments[kwargs_param\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m kwargs\n\u001b[0;32m   3033\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3034\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   3035\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgot an unexpected keyword argument \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   3036\u001b[0m                 arg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))))\n\u001b[0;32m   3038\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_arguments_cls(\u001b[38;5;28mself\u001b[39m, arguments)\n",
      "\u001b[1;31mTypeError\u001b[0m: got an unexpected keyword argument 'squared'"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "# 1) Ler o CSV (usa sep=\";\", decimal=\",\" e milhares=\".\")\n",
    "df = pd.read_csv(\n",
    "   r\"C:\\Users\\kinagaki\\OneDrive - Digicorner\\Desktop\\Trabalho de Conclusão de Curso - UFRJ.2025\\Correção\\versão atualizada\\TESTE BOVA 11\\bova11_ate_2023.csv\",\n",
    "   sep=\";\", decimal=\",\", thousands=\".\"\n",
    ")\n",
    "# 2) Normalizar headers\n",
    "df.columns = (df.columns\n",
    "               .str.strip()\n",
    "               .str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "               .str.lower())\n",
    "# 3) Renomear para os nomes usados no modelo (ajuste se seu header estiver diferente)\n",
    "rename_map = {\n",
    "   'data': 'date',\n",
    "   'ultimo': 'close', 'último': 'close',  # caso venha \"Último\"\n",
    "   'retorno_mensal_(%)': 'ret_m', 'retorno_mensal': 'ret_m', 'ret_m': 'ret_m',\n",
    "   'média_móvel_3m': 'mm3', 'media_movel_3m': 'mm3',\n",
    "   'média_móvel_6m': 'mm6', 'media_movel_6m': 'mm6',\n",
    "   'média_móvel_12m': 'mm12','media_movel_12m': 'mm12',\n",
    "   'volatilidade_3m': 'vol3', 'vol3': 'vol3',\n",
    "   'volatilidade_6m': 'vol6', 'vol6': 'vol6',\n",
    "   'momentum': 'momentum3', 'momentum3': 'momentum3',\n",
    "   'volume_relativo': 'volrel', 'volrel': 'volrel',\n",
    "   'close_plus1': 'close_plus1', 'close_+1': 'close_plus1'\n",
    "}\n",
    "df = df.rename(columns={k:v for k,v in rename_map.items() if k in df.columns})\n",
    "# 4) Datas\n",
    "df['date'] = pd.to_datetime(df['date'], dayfirst=True, errors='coerce')\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "# 5) Limpeza e conversão numérica robusta\n",
    "num_cols = ['close','ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel','close_plus1']\n",
    "for c in num_cols:\n",
    "   if c in df.columns:\n",
    "       df[c] = (df[c].astype(str)\n",
    "                      .str.replace('\\u00A0', '', regex=False)  # espaço não-quebrante\n",
    "                      .str.replace('%', '', regex=False)\n",
    "                      .str.replace(' ', '', regex=False))\n",
    "       # Se seu CSV já veio com decimal=\",\", thousands=\".\" isso normalmente basta:\n",
    "       df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "# 6) Checagens\n",
    "print(\"Dtypes:\\n\", df[num_cols].dtypes)\n",
    "print(\"\\nNaN por coluna:\\n\", df[num_cols].isna().sum())\n",
    "assert pd.isna(df.loc[len(df)-1, 'close_plus1']), \"A última linha (dez/2023) deve estar vazia em close_plus1.\"\n",
    "# 7) Montar treino\n",
    "FEATS  = ['ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel']\n",
    "TARGET = 'close_plus1'\n",
    "train = df.dropna(subset=FEATS + [TARGET]).copy()\n",
    "print(\"\\nLinhas totais:\", len(df), \" | Linhas após dropna:\", len(train))\n",
    "assert len(train) >= 12, \"Poucos dados após limpeza; verifique colunas renomeadas e conversão numérica.\"\n",
    "X = train[FEATS].values\n",
    "y = train[TARGET].values\n",
    "# 8) Ridge com OOF\n",
    "tscv  = TimeSeriesSplit(n_splits=5)\n",
    "ridge = Pipeline([('scaler', StandardScaler()), ('m', Ridge())])\n",
    "grid  = {'m__alpha': [0.1, 0.5, 1.0, 2.0, 5.0]}\n",
    "g = GridSearchCV(ridge, grid, cv=tscv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "g.fit(X, y)\n",
    "best_ridge = g.best_estimator_\n",
    "y_oof = np.full_like(y, np.nan, dtype=float)\n",
    "for tr, te in tscv.split(X):\n",
    "   best_ridge.fit(X[tr], y[tr])\n",
    "   y_oof[te] = best_ridge.predict(X[te])\n",
    "mask = ~np.isnan(y_oof)\n",
    "mae  = mean_absolute_error(y[mask], y_oof[mask])\n",
    "rmse = mean_squared_error(y[mask], y_oof[mask], squared=False)\n",
    "r2   = r2_score(y[mask], y_oof[mask])\n",
    "print(f\"\\nRidge | MAE={mae:.3f}  RMSE={rmse:.3f}  R²={r2:.3f}  best={g.best_params_}\")\n",
    "# 9) Projeção recursiva JAN–DEZ/2024\n",
    "def roll_mean(a,n): return np.mean(a[-n:]) if len(a)>=n else np.nan\n",
    "def roll_std(a,n):  return np.std(a[-n:], ddof=1) if len(a)>=n else np.nan\n",
    "work = df[['date','close','ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel']].copy()\n",
    "volrel_last3 = work['volrel'].tail(3).mean()\n",
    "last_close   = work['close'].iloc[-1]\n",
    "rows = []\n",
    "for _ in range(12):\n",
    "   feats_now = work.iloc[-1][FEATS].to_dict()\n",
    "   feats_now['volrel'] = volrel_last3\n",
    "   x = np.array([feats_now[f] for f in FEATS], dtype=float).reshape(1,-1)\n",
    "   pred_close_next = float(best_ridge.predict(x)[0])\n",
    "   next_date = work['date'].iloc[-1] + pd.offsets.MonthBegin(1)\n",
    "   ret_next  = (pred_close_next / last_close) - 1.0\n",
    "   # anexa a nova linha e recalcula features\n",
    "   work = pd.concat([work, pd.DataFrame([{\n",
    "       'date': next_date, 'close': pred_close_next, 'ret_m': ret_next, 'volrel': volrel_last3\n",
    "   }])], ignore_index=True)\n",
    "   closes = work['close'].values\n",
    "   rets   = work['ret_m'].values\n",
    "   work.loc[work.index[-1],'mm3']  = roll_mean(closes, 3)\n",
    "   work.loc[work.index[-1],'mm6']  = roll_mean(closes, 6)\n",
    "   work.loc[work.index[-1],'mm12'] = roll_mean(closes,12)\n",
    "   work.loc[work.index[-1],'vol3'] = roll_std(rets, 3)\n",
    "   work.loc[work.index[-1],'vol6'] = roll_std(rets, 6)\n",
    "   if len(closes) >= 4:\n",
    "       work.loc[work.index[-1],'momentum3'] = (closes[-1]/closes[-4]) - 1\n",
    "   last_close = pred_close_next\n",
    "   rows.append({'date': next_date, 'close_pred': pred_close_next})\n",
    "pred_ridge = pd.DataFrame(rows)\n",
    "# 10) Salvar Excel\n",
    "try:\n",
    "   with pd.ExcelWriter('bova11_pred_2024_ridge.xlsx', engine='xlsxwriter') as w:\n",
    "       pred_ridge.to_excel(w, index=False, sheet_name='predicoes_2024')\n",
    "       pd.DataFrame([{'MAE':mae,'RMSE':rmse,'R2':r2, **g.best_params_}]).to_excel(w, index=False, sheet_name='metricas')\n",
    "except Exception:\n",
    "   with pd.ExcelWriter('bova11_pred_2024_ridge.xlsx', engine='openpyxl') as w:\n",
    "       pred_ridge.to_excel(w, index=False, sheet_name='predicoes_2024')\n",
    "       pd.DataFrame([{'MAE':mae,'RMSE':rmse,'R2':r2, **g.best_params_}]).to_excel(w, index=False, sheet_name='metricas')\n",
    "print(\"\\nArquivo gerado: bova11_pred_2024_ridge.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f537f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dtypes:\n",
      " close          float64\n",
      "ret_m          float64\n",
      "mm3            float64\n",
      "mm6            float64\n",
      "mm12           float64\n",
      "vol3           float64\n",
      "vol6           float64\n",
      "momentum3      float64\n",
      "volrel         float64\n",
      "close_plus1    float64\n",
      "dtype: object\n",
      "\n",
      "NaN por coluna:\n",
      " close          0\n",
      "ret_m          0\n",
      "mm3            0\n",
      "mm6            0\n",
      "mm12           0\n",
      "vol3           0\n",
      "vol6           0\n",
      "momentum3      0\n",
      "volrel         0\n",
      "close_plus1    1\n",
      "dtype: int64\n",
      "\n",
      "Linhas totais: 48  | Linhas após dropna: 47\n",
      "\n",
      "Ridge  | MAE=1.910  RMSE=2.494  R²=0.875  best={'m__alpha': 0.1}\n",
      "\n",
      "✅ Arquivo gerado: bova11_pred_2024_ridge.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "# 1) Ler CSV (ajuste o caminho conforme necessário)\n",
    "df = pd.read_csv(\n",
    "   r\"C:\\Users\\kinagaki\\OneDrive - Digicorner\\Desktop\\Trabalho de Conclusão de Curso - UFRJ.2025\\Correção\\versão atualizada\\TESTE BOVA 11\\bova11_ate_2023.csv\",\n",
    "   sep=\";\", decimal=\",\", thousands=\".\"\n",
    ")\n",
    "# 2) Normalizar cabeçalhos\n",
    "df.columns = (df.columns\n",
    "               .str.strip()\n",
    "               .str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "               .str.lower())\n",
    "# 3) Renomear colunas conforme padrão\n",
    "rename_map = {\n",
    "   'data': 'date',\n",
    "   'ultimo': 'close', 'último': 'close',\n",
    "   'retorno_mensal_(%)': 'ret_m', 'retorno_mensal': 'ret_m',\n",
    "   'média_móvel_3m': 'mm3', 'media_movel_3m': 'mm3',\n",
    "   'média_móvel_6m': 'mm6', 'media_movel_6m': 'mm6',\n",
    "   'média_móvel_12m': 'mm12','media_movel_12m': 'mm12',\n",
    "   'volatilidade_3m': 'vol3', 'vol3': 'vol3',\n",
    "   'volatilidade_6m': 'vol6', 'vol6': 'vol6',\n",
    "   'momentum': 'momentum3', 'momentum3': 'momentum3',\n",
    "   'volume_relativo': 'volrel', 'volrel': 'volrel',\n",
    "   'close_plus1': 'close_plus1', 'close_+1': 'close_plus1'\n",
    "}\n",
    "df = df.rename(columns={k:v for k,v in rename_map.items() if k in df.columns})\n",
    "# 4) Converter datas\n",
    "df['date'] = pd.to_datetime(df['date'], dayfirst=True, errors='coerce')\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "# 5) Converter colunas numéricas (limpando caracteres)\n",
    "num_cols = ['close','ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel','close_plus1']\n",
    "for c in num_cols:\n",
    "   if c in df.columns:\n",
    "       df[c] = (df[c].astype(str)\n",
    "                      .str.replace('\\u00A0','',regex=False)\n",
    "                      .str.replace('%','',regex=False)\n",
    "                      .str.replace(' ','',regex=False))\n",
    "       df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "# 6) Checar integridade\n",
    "print(\"Dtypes:\\n\", df[num_cols].dtypes)\n",
    "print(\"\\nNaN por coluna:\\n\", df[num_cols].isna().sum())\n",
    "assert pd.isna(df.loc[len(df)-1, 'close_plus1']), \"A última linha (dez/2023) deve estar vazia em close_plus1.\"\n",
    "# 7) Treino\n",
    "FEATS  = ['ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel']\n",
    "TARGET = 'close_plus1'\n",
    "train = df.dropna(subset=FEATS + [TARGET]).copy()\n",
    "print(\"\\nLinhas totais:\", len(df), \" | Linhas após dropna:\", len(train))\n",
    "assert len(train) >= 12, \"Poucos dados após limpeza.\"\n",
    "X = train[FEATS].values\n",
    "y = train[TARGET].values\n",
    "# 8) Modelo Ridge + validação temporal\n",
    "tscv  = TimeSeriesSplit(n_splits=5)\n",
    "ridge = Pipeline([('scaler', StandardScaler()), ('m', Ridge())])\n",
    "grid  = {'m__alpha': [0.1, 0.5, 1.0, 2.0, 5.0]}\n",
    "g = GridSearchCV(ridge, grid, cv=tscv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "g.fit(X, y)\n",
    "best_ridge = g.best_estimator_\n",
    "# 9) Validação out-of-fold\n",
    "y_oof = np.full_like(y, np.nan, dtype=float)\n",
    "for tr, te in tscv.split(X):\n",
    "   best_ridge.fit(X[tr], y[tr])\n",
    "   y_oof[te] = best_ridge.predict(X[te])\n",
    "mask = ~np.isnan(y_oof)\n",
    "mae  = mean_absolute_error(y[mask], y_oof[mask])\n",
    "mse  = mean_squared_error(y[mask], y_oof[mask])\n",
    "rmse = np.sqrt(mse)\n",
    "r2   = r2_score(y[mask], y_oof[mask])\n",
    "print(f\"\\nRidge  | MAE={mae:.3f}  RMSE={rmse:.3f}  R²={r2:.3f}  best={g.best_params_}\")\n",
    "# 10) Projeção recursiva JAN–DEZ/2024\n",
    "def roll_mean(a,n): return np.mean(a[-n:]) if len(a)>=n else np.nan\n",
    "def roll_std(a,n):  return np.std(a[-n:], ddof=1) if len(a)>=n else np.nan\n",
    "work = df[['date','close','ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel']].copy()\n",
    "volrel_last3 = work['volrel'].tail(3).mean()\n",
    "last_close   = work['close'].iloc[-1]\n",
    "rows = []\n",
    "for _ in range(12):  # 12 meses de 2024\n",
    "   feats_now = work.iloc[-1][FEATS].to_dict()\n",
    "   feats_now['volrel'] = volrel_last3\n",
    "   x = np.array([feats_now[f] for f in FEATS], dtype=float).reshape(1, -1)\n",
    "   pred_close_next = float(best_ridge.predict(x)[0])\n",
    "   next_date = work['date'].iloc[-1] + pd.offsets.MonthBegin(1)\n",
    "   ret_next  = (pred_close_next / last_close) - 1.0\n",
    "   # anexa linha prevista\n",
    "   work = pd.concat([work, pd.DataFrame([{\n",
    "       'date': next_date, 'close': pred_close_next, 'ret_m': ret_next, 'volrel': volrel_last3\n",
    "   }])], ignore_index=True)\n",
    "   # recalcula features\n",
    "   closes = work['close'].values\n",
    "   rets   = work['ret_m'].values\n",
    "   work.loc[work.index[-1], 'mm3']  = roll_mean(closes, 3)\n",
    "   work.loc[work.index[-1], 'mm6']  = roll_mean(closes, 6)\n",
    "   work.loc[work.index[-1], 'mm12'] = roll_mean(closes,12)\n",
    "   work.loc[work.index[-1], 'vol3'] = roll_std(rets, 3)\n",
    "   work.loc[work.index[-1], 'vol6'] = roll_std(rets, 6)\n",
    "   if len(closes) >= 4:\n",
    "       work.loc[work.index[-1], 'momentum3'] = (closes[-1]/closes[-4]) - 1\n",
    "   last_close = pred_close_next\n",
    "   rows.append({'date': next_date, 'close_pred': pred_close_next})\n",
    "pred_ridge = pd.DataFrame(rows)\n",
    "# 11) Salvar em Excel\n",
    "try:\n",
    "   with pd.ExcelWriter('bova11_pred_2024_ridge.xlsx', engine='xlsxwriter') as w:\n",
    "       pred_ridge.to_excel(w, index=False, sheet_name='predicoes_2024')\n",
    "       pd.DataFrame([{'MAE':mae,'RMSE':rmse,'R2':r2, **g.best_params_}]).to_excel(w, index=False, sheet_name='metricas')\n",
    "except Exception:\n",
    "   with pd.ExcelWriter('bova11_pred_2024_ridge.xlsx', engine='openpyxl') as w:\n",
    "       pred_ridge.to_excel(w, index=False, sheet_name='predicoes_2024')\n",
    "       pd.DataFrame([{'MAE':mae,'RMSE':rmse,'R2':r2, **g.best_params_}]).to_excel(w, index=False, sheet_name='metricas')\n",
    "print(\"\\n✅ Arquivo gerado: bova11_pred_2024_ridge.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6e5c591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dtypes:\n",
      " close          float64\n",
      "ret_m          float64\n",
      "mm3            float64\n",
      "mm6            float64\n",
      "mm12           float64\n",
      "vol3           float64\n",
      "vol6           float64\n",
      "momentum3      float64\n",
      "volrel         float64\n",
      "close_plus1    float64\n",
      "dtype: object\n",
      "\n",
      "NaN por coluna:\n",
      " close          0\n",
      "ret_m          0\n",
      "mm3            0\n",
      "mm6            0\n",
      "mm12           0\n",
      "vol3           0\n",
      "vol6           0\n",
      "momentum3      0\n",
      "volrel         0\n",
      "close_plus1    1\n",
      "dtype: int64\n",
      "\n",
      "Linhas totais: 48  | Linhas após dropna: 47\n",
      "\n",
      "Ridge  | MAE=1.910  RMSE=2.494  R²=0.875  best={'m__alpha': 0.1}\n",
      "\n",
      "✅ Arquivo gerado em:\n",
      "C:\\Users\\kinagaki\\OneDrive - Digicorner\\Desktop\\Trabalho de Conclusão de Curso - UFRJ.2025\\Correção\\versão atualizada\\TESTE BOVA 11\\bova11_pred_2024_ridge.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "# =========================================================\n",
    "# 1) Caminhos / leitura\n",
    "# =========================================================\n",
    "INPUT_PATH = r\"C:\\Users\\kinagaki\\OneDrive - Digicorner\\Desktop\\Trabalho de Conclusão de Curso - UFRJ.2025\\Correção\\versão atualizada\\TESTE BOVA 11\\bova11_ate_2023.csv\"\n",
    "BASE_DIR   = os.path.dirname(INPUT_PATH)\n",
    "OUTPUT_PATH = os.path.join(BASE_DIR, \"bova11_pred_2024_ridge.xlsx\")\n",
    "df = pd.read_csv(INPUT_PATH, sep=\";\", decimal=\",\", thousands=\".\")\n",
    "# =========================================================\n",
    "# 2) Padronização de colunas / tipos\n",
    "# =========================================================\n",
    "df.columns = (df.columns\n",
    "               .str.strip()\n",
    "               .str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "               .str.lower())\n",
    "rename_map = {\n",
    "   'data': 'date',\n",
    "   'ultimo': 'close', 'último': 'close',\n",
    "   'retorno_mensal_(%)': 'ret_m', 'retorno_mensal': 'ret_m',\n",
    "   'média_móvel_3m': 'mm3', 'media_movel_3m': 'mm3',\n",
    "   'média_móvel_6m': 'mm6', 'media_movel_6m': 'mm6',\n",
    "   'média_móvel_12m': 'mm12','media_movel_12m': 'mm12',\n",
    "   'volatilidade_3m': 'vol3', 'vol3': 'vol3',\n",
    "   'volatilidade_6m': 'vol6', 'vol6': 'vol6',\n",
    "   'momentum': 'momentum3', 'momentum3': 'momentum3',\n",
    "   'volume_relativo': 'volrel', 'volrel': 'volrel',\n",
    "   'close_plus1': 'close_plus1', 'close_+1': 'close_plus1'\n",
    "}\n",
    "df = df.rename(columns={k:v for k,v in rename_map.items() if k in df.columns})\n",
    "df['date'] = pd.to_datetime(df['date'], dayfirst=True, errors='coerce')\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "num_cols = ['close','ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel','close_plus1']\n",
    "for c in num_cols:\n",
    "   if c in df.columns:\n",
    "       df[c] = (df[c].astype(str)\n",
    "                      .str.replace('\\u00A0','',regex=False)\n",
    "                      .str.replace('%','',regex=False)\n",
    "                      .str.replace(' ','',regex=False))\n",
    "       df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "print(\"Dtypes:\\n\", df[num_cols].dtypes)\n",
    "print(\"\\nNaN por coluna:\\n\", df[num_cols].isna().sum())\n",
    "assert pd.isna(df.loc[len(df)-1, 'close_plus1']), \"A última linha (dez/2023) deve estar vazia em close_plus1.\"\n",
    "# =========================================================\n",
    "# 3) Treino (Ridge) com validação temporal\n",
    "# =========================================================\n",
    "FEATS  = ['ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel']\n",
    "TARGET = 'close_plus1'\n",
    "train = df.dropna(subset=FEATS + [TARGET]).copy()\n",
    "print(\"\\nLinhas totais:\", len(df), \" | Linhas após dropna:\", len(train))\n",
    "assert len(train) >= 12, \"Poucos dados após limpeza.\"\n",
    "X = train[FEATS].values\n",
    "y = train[TARGET].values\n",
    "tscv  = TimeSeriesSplit(n_splits=5)\n",
    "ridge = Pipeline([('scaler', StandardScaler()), ('m', Ridge())])\n",
    "grid  = {'m__alpha': [0.1, 0.5, 1.0, 2.0, 5.0]}\n",
    "g = GridSearchCV(ridge, grid, cv=tscv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "g.fit(X, y)\n",
    "best_ridge = g.best_estimator_\n",
    "# OOF com máscara\n",
    "y_oof = np.full_like(y, np.nan, dtype=float)\n",
    "for tr, te in tscv.split(X):\n",
    "   best_ridge.fit(X[tr], y[tr])\n",
    "   y_oof[te] = best_ridge.predict(X[te])\n",
    "mask = ~np.isnan(y_oof)\n",
    "mae  = mean_absolute_error(y[mask], y_oof[mask])\n",
    "mse  = mean_squared_error(y[mask], y_oof[mask])\n",
    "rmse = np.sqrt(mse)\n",
    "r2   = r2_score(y[mask], y_oof[mask])\n",
    "print(f\"\\nRidge  | MAE={mae:.3f}  RMSE={rmse:.3f}  R²={r2:.3f}  best={g.best_params_}\")\n",
    "# =========================================================\n",
    "# 4) Projeção recursiva JAN–DEZ/2024 (sem macro)\n",
    "# =========================================================\n",
    "def roll_mean(a,n): return np.mean(a[-n:]) if len(a)>=n else np.nan\n",
    "def roll_std(a,n):  return np.std(a[-n:], ddof=1) if len(a)>=n else np.nan\n",
    "work = df[['date','close','ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel']].copy()\n",
    "volrel_last3 = work['volrel'].tail(3).mean()\n",
    "last_close   = work['close'].iloc[-1]\n",
    "rows = []\n",
    "for _ in range(12):  # 12 meses de 2024\n",
    "   feats_now = work.iloc[-1][FEATS].to_dict()\n",
    "   feats_now['volrel'] = volrel_last3\n",
    "   x = np.array([feats_now[f] for f in FEATS], dtype=float).reshape(1, -1)\n",
    "   pred_close_next = float(best_ridge.predict(x)[0])\n",
    "   next_date = work['date'].iloc[-1] + pd.offsets.MonthBegin(1)\n",
    "   ret_next  = (pred_close_next / last_close) - 1.0\n",
    "   # adiciona linha prevista\n",
    "   work = pd.concat([work, pd.DataFrame([{\n",
    "       'date': next_date, 'close': pred_close_next, 'ret_m': ret_next, 'volrel': volrel_last3\n",
    "   }])], ignore_index=True)\n",
    "   # recalcula features\n",
    "   closes = work['close'].values\n",
    "   rets   = work['ret_m'].values\n",
    "   work.loc[work.index[-1], 'mm3']  = roll_mean(closes, 3)\n",
    "   work.loc[work.index[-1], 'mm6']  = roll_mean(closes, 6)\n",
    "   work.loc[work.index[-1], 'mm12'] = roll_mean(closes,12)\n",
    "   work.loc[work.index[-1], 'vol3'] = roll_std(rets, 3)\n",
    "   work.loc[work.index[-1], 'vol6'] = roll_std(rets, 6)\n",
    "   if len(closes) >= 4:\n",
    "       work.loc[work.index[-1], 'momentum3'] = (closes[-1]/closes[-4]) - 1\n",
    "   last_close = pred_close_next\n",
    "   rows.append({'date': next_date, 'close_pred': pred_close_next})\n",
    "pred_ridge = pd.DataFrame(rows)\n",
    "# =========================================================\n",
    "# 5) Salvar Excel no mesmo diretório do CSV\n",
    "# =========================================================\n",
    "try:\n",
    "   with pd.ExcelWriter(OUTPUT_PATH, engine='xlsxwriter') as w:\n",
    "       pred_ridge.to_excel(w, index=False, sheet_name='predicoes_2024')\n",
    "       pd.DataFrame([{'MAE':mae,'RMSE':rmse,'R2':r2, **g.best_params_}]).to_excel(w, index=False, sheet_name='metricas')\n",
    "except Exception:\n",
    "   with pd.ExcelWriter(OUTPUT_PATH, engine='openpyxl') as w:\n",
    "       pred_ridge.to_excel(w, index=False, sheet_name='predicoes_2024')\n",
    "       pd.DataFrame([{'MAE':mae,'RMSE':rmse,'R2':r2, **g.best_params_}]).to_excel(w, index=False, sheet_name='metricas')\n",
    "print(f\"\\n✅ Arquivo gerado em:\\n{OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c8c13dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linhas histórico (<=2023-12): 48\n",
      "Linhas 2024 (se houver no CSV): 0\n",
      "Linhas após dropna (treino): 47\n",
      "\n",
      "Ridge  | (Histórico 2020–2023)  MAE=1.910  RMSE=2.494  R²=0.875  best={'m__alpha': 0.1}\n",
      "\n",
      "✅ Arquivo gerado em:\n",
      "C:\\Users\\kinagaki\\OneDrive - Digicorner\\Desktop\\Trabalho de Conclusão de Curso - UFRJ.2025\\Correção\\versão atualizada\\TESTE BOVA 11\\bova11_pred_2024_ridge.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "# =========================================================\n",
    "# 1) Caminhos / leitura\n",
    "# =========================================================\n",
    "INPUT_PATH = r\"C:\\Users\\kinagaki\\OneDrive - Digicorner\\Desktop\\Trabalho de Conclusão de Curso - UFRJ.2025\\Correção\\versão atualizada\\TESTE BOVA 11\\bova11_ate_2023.csv\"\n",
    "BASE_DIR   = os.path.dirname(INPUT_PATH)\n",
    "OUTPUT_PATH = os.path.join(BASE_DIR, \"bova11_pred_2024_ridge.xlsx\")\n",
    "df = pd.read_csv(INPUT_PATH, sep=\";\", decimal=\",\", thousands=\".\")\n",
    "# =========================================================\n",
    "# 2) Padronização de colunas / tipos\n",
    "# =========================================================\n",
    "df.columns = (df.columns\n",
    "               .str.strip()\n",
    "               .str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "               .str.lower())\n",
    "rename_map = {\n",
    "   'data': 'date',\n",
    "   'ultimo': 'close', 'último': 'close',\n",
    "   'retorno_mensal_(%)': 'ret_m', 'retorno_mensal': 'ret_m',\n",
    "   'média_móvel_3m': 'mm3', 'media_movel_3m': 'mm3',\n",
    "   'média_móvel_6m': 'mm6', 'media_movel_6m': 'mm6',\n",
    "   'média_móvel_12m': 'mm12','media_movel_12m': 'mm12',\n",
    "   'volatilidade_3m': 'vol3', 'vol3': 'vol3',\n",
    "   'volatilidade_6m': 'vol6', 'vol6': 'vol6',\n",
    "   'momentum': 'momentum3', 'momentum3': 'momentum3',\n",
    "   'volume_relativo': 'volrel', 'volrel': 'volrel',\n",
    "   'close_plus1': 'close_plus1', 'close_+1': 'close_plus1'\n",
    "}\n",
    "df = df.rename(columns={k:v for k,v in rename_map.items() if k in df.columns})\n",
    "df['date'] = pd.to_datetime(df['date'], dayfirst=True, errors='coerce')\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "num_cols = ['close','ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel','close_plus1']\n",
    "for c in num_cols:\n",
    "   if c in df.columns:\n",
    "       df[c] = (df[c].astype(str)\n",
    "                      .str.replace('\\u00A0','',regex=False)\n",
    "                      .str.replace('%','',regex=False)\n",
    "                      .str.replace(' ','',regex=False))\n",
    "       df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "# =========================================================\n",
    "# 3) Separar histórico (até 2023-12) e, opcionalmente, reais de 2024\n",
    "#    -> Treino usa SOMENTE df_hist (sem qualquer 2024)\n",
    "# =========================================================\n",
    "limite_hist = pd.Timestamp('2023-12-01')  # 1º dia de dez/2023\n",
    "df_hist = df[df['date'] <= limite_hist].copy()\n",
    "df_2024 = df[(df['date'] >= pd.Timestamp('2024-01-01')) & (df['date'] <= pd.Timestamp('2024-12-31'))][['date','close']].copy()\n",
    "df_2024.rename(columns={'close':'close_real'}, inplace=True)\n",
    "# Se sua base é “até 2023”, a assert abaixo garante que a última linha é a que vamos prever (jan/24)\n",
    "if 'close_plus1' in df_hist.columns:\n",
    "   assert pd.isna(df_hist.loc[len(df_hist)-1, 'close_plus1']), \"A última linha de 2023 deve estar vazia em close_plus1 (alvo desconhecido).\"\n",
    "print(\"Linhas histórico (<=2023-12):\", len(df_hist))\n",
    "print(\"Linhas 2024 (se houver no CSV):\", len(df_2024))\n",
    "# =========================================================\n",
    "# 4) Treino (Ridge) com validação temporal (somente 2020–2023)\n",
    "# =========================================================\n",
    "FEATS  = ['ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel']\n",
    "TARGET = 'close_plus1'\n",
    "train = df_hist.dropna(subset=FEATS + [TARGET]).copy()\n",
    "print(\"Linhas após dropna (treino):\", len(train))\n",
    "assert len(train) >= 12, \"Poucos dados após limpeza.\"\n",
    "X = train[FEATS].values\n",
    "y = train[TARGET].values\n",
    "tscv  = TimeSeriesSplit(n_splits=5)\n",
    "ridge = Pipeline([('scaler', StandardScaler()), ('m', Ridge())])\n",
    "grid  = {'m__alpha': [0.1, 0.5, 1.0, 2.0, 5.0]}\n",
    "g = GridSearchCV(ridge, grid, cv=tscv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "g.fit(X, y)\n",
    "best_ridge = g.best_estimator_\n",
    "# OOF com máscara (métricas apenas no histórico)\n",
    "y_oof = np.full_like(y, np.nan, dtype=float)\n",
    "for tr, te in tscv.split(X):\n",
    "   best_ridge.fit(X[tr], y[tr])\n",
    "   y_oof[te] = best_ridge.predict(X[te])\n",
    "mask = ~np.isnan(y_oof)\n",
    "mae  = mean_absolute_error(y[mask], y_oof[mask])\n",
    "mse  = mean_squared_error(y[mask], y_oof[mask])\n",
    "rmse = np.sqrt(mse)\n",
    "r2   = r2_score(y[mask], y_oof[mask])\n",
    "print(f\"\\nRidge  | (Histórico 2020–2023)  MAE={mae:.3f}  RMSE={rmse:.3f}  R²={r2:.3f}  best={g.best_params_}\")\n",
    "# =========================================================\n",
    "# 5) Projeção recursiva: gerar exatamente 12 datas de 2024 (sem usar 2024 real)\n",
    "# =========================================================\n",
    "def roll_mean(a,n): return np.mean(a[-n:]) if len(a)>=n else np.nan\n",
    "def roll_std(a,n):  return np.std(a[-n:], ddof=1) if len(a)>=n else np.nan\n",
    "# base de trabalho começa no histórico (até 2023-12)\n",
    "work = df_hist[['date','close','ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel']].copy()\n",
    "volrel_last3 = work['volrel'].tail(3).mean()\n",
    "last_close   = work['close'].iloc[-1]\n",
    "alvos_2024 = pd.date_range('2024-01-01', '2024-12-01', freq='MS')  # 12 meses fixos\n",
    "rows = []\n",
    "for next_date in alvos_2024:\n",
    "   feats_now = work.iloc[-1][FEATS].to_dict()\n",
    "   feats_now['volrel'] = volrel_last3  # hipótese para o mês seguinte\n",
    "   x = np.array([feats_now[f] for f in FEATS], dtype=float).reshape(1, -1)\n",
    "   pred_close_next = float(best_ridge.predict(x)[0])\n",
    "   ret_next  = (pred_close_next / last_close) - 1.0\n",
    "   # anexa linha prevista\n",
    "   work = pd.concat([work, pd.DataFrame([{\n",
    "       'date': next_date, 'close': pred_close_next, 'ret_m': ret_next, 'volrel': volrel_last3\n",
    "   }])], ignore_index=True)\n",
    "   # recalcula features na nova última linha\n",
    "   closes = work['close'].values\n",
    "   rets   = work['ret_m'].values\n",
    "   work.loc[work.index[-1], 'mm3']  = roll_mean(closes, 3)\n",
    "   work.loc[work.index[-1], 'mm6']  = roll_mean(closes, 6)\n",
    "   work.loc[work.index[-1], 'mm12'] = roll_mean(closes,12)\n",
    "   work.loc[work.index[-1], 'vol3'] = roll_std(rets, 3)\n",
    "   work.loc[work.index[-1], 'vol6'] = roll_std(rets, 6)\n",
    "   if len(closes) >= 4:\n",
    "       work.loc[work.index[-1], 'momentum3'] = (closes[-1]/closes[-4]) - 1\n",
    "   last_close = pred_close_next\n",
    "   rows.append({'date': next_date, 'close_pred': pred_close_next})\n",
    "pred_2024 = pd.DataFrame(rows).sort_values('date').reset_index(drop=True)\n",
    "# =========================================================\n",
    "# 6) (Opcional) Avaliar contra reais de 2024, se existirem no CSV\n",
    "#     -> NÃO são usados no treino; apenas comparação em holdout\n",
    "# =========================================================\n",
    "avaliacao_2024 = None\n",
    "if len(df_2024) > 0:\n",
    "   avaliacao_2024 = pred_2024.merge(df_2024, on='date', how='left')\n",
    "   if 'close_real' in avaliacao_2024.columns and avaliacao_2024['close_real'].notna().any():\n",
    "       avaliacao_2024['erro_abs'] = (avaliacao_2024['close_pred'] - avaliacao_2024['close_real']).abs()\n",
    "       avaliacao_2024['erro_%']   = (avaliacao_2024['close_pred'] / avaliacao_2024['close_real'] - 1.0) * 100\n",
    "       mae_24  = avaliacao_2024['erro_abs'].mean(skipna=True)\n",
    "       rmse_24 = np.sqrt(((avaliacao_2024['close_pred'] - avaliacao_2024['close_real'])**2).mean(skipna=True))\n",
    "       print(f\"\\n(Comparação holdout 2024) MAE={mae_24:.3f}  RMSE={rmse_24:.3f}  (onde houver real)\")\n",
    "   else:\n",
    "       print(\"\\nSem closes reais de 2024 no CSV; apenas previsões foram geradas.\")\n",
    "# =========================================================\n",
    "# 7) Salvar Excel no mesmo diretório do CSV\n",
    "# =========================================================\n",
    "try:\n",
    "   with pd.ExcelWriter(OUTPUT_PATH, engine='xlsxwriter') as w:\n",
    "       pred_2024.to_excel(w, index=False, sheet_name='predicoes_2024')  # só 2024\n",
    "       pd.DataFrame([{'MAE_hist':mae,'RMSE_hist':rmse,'R2_hist':r2, **g.best_params_}]).to_excel(w, index=False, sheet_name='metricas_hist')\n",
    "       if avaliacao_2024 is not None:\n",
    "           avaliacao_2024.to_excel(w, index=False, sheet_name='avaliacao_2024')\n",
    "except Exception:\n",
    "   with pd.ExcelWriter(OUTPUT_PATH, engine='openpyxl') as w:\n",
    "       pred_2024.to_excel(w, index=False, sheet_name='predicoes_2024')\n",
    "       pd.DataFrame([{'MAE_hist':mae,'RMSE_hist':rmse,'R2_hist':r2, **g.best_params_}]).to_excel(w, index=False, sheet_name='metricas_hist')\n",
    "       if avaliacao_2024 is not None:\n",
    "           avaliacao_2024.to_excel(w, index=False, sheet_name='avaliacao_2024')\n",
    "print(f\"\\n✅ Arquivo gerado em:\\n{OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a581db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m pred[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(pred[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     18\u001b[0m real\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m real\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m---> 19\u001b[0m real[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mreal\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, dayfirst\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     20\u001b[0m real \u001b[38;5;241m=\u001b[39m real\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124multimo\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124múltimo\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfechamento\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# =========================================================\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Merge (junção real + previsto)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# =========================================================\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date'"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# =========================================================\n",
    "# Caminhos dos arquivos\n",
    "# =========================================================\n",
    "BASE_DIR = r\"C:\\Users\\kinagaki\\OneDrive - Digicorner\\Desktop\\Trabalho de Conclusão de Curso - UFRJ.2025\\Correção\\versão atualizada\\TESTE BOVA 11\"\n",
    "PRED_PATH = os.path.join(BASE_DIR, \"bova11_pred_2024_ridge.xlsx\")      # arquivo do modelo\n",
    "REAL_PATH = os.path.join(BASE_DIR, \"bova11_real_2024.csv\")             # seu arquivo com dados reais\n",
    "# =========================================================\n",
    "# Leitura\n",
    "# =========================================================\n",
    "pred = pd.read_excel(PRED_PATH, sheet_name='predicoes_2024')\n",
    "real = pd.read_csv(REAL_PATH, sep=\";\", decimal=\",\", thousands=\".\")\n",
    "# Ajusta formatos\n",
    "pred['date'] = pd.to_datetime(pred['date'])\n",
    "real.columns = real.columns.str.strip().str.lower()\n",
    "real['date'] = pd.to_datetime(real['date'], dayfirst=True, errors='coerce')\n",
    "real = real.rename(columns={'ultimo':'close','último':'close','fechamento':'close'})\n",
    "# =========================================================\n",
    "# Merge (junção real + previsto)\n",
    "# =========================================================\n",
    "comp = pd.merge(pred, real[['date','close']], on='date', how='inner')\n",
    "comp.rename(columns={'close':'close_real','close_pred':'close_pred'}, inplace=True)\n",
    "comp['erro_abs'] = (comp['close_pred'] - comp['close_real']).abs()\n",
    "comp['erro_%']   = (comp['close_pred']/comp['close_real'] - 1)*100\n",
    "# =========================================================\n",
    "# Métricas\n",
    "# =========================================================\n",
    "mae  = mean_absolute_error(comp['close_real'], comp['close_pred'])\n",
    "rmse = np.sqrt(mean_squared_error(comp['close_real'], comp['close_pred']))\n",
    "r2   = r2_score(comp['close_real'], comp['close_pred'])\n",
    "print(\"Comparação 2024:\")\n",
    "print(f\"MAE = {mae:.3f}  |  RMSE = {rmse:.3f}  |  R² = {r2:.3f}\")\n",
    "# =========================================================\n",
    "# 2️⃣ Gráfico real vs previsto\n",
    "# =========================================================\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(comp['date'], comp['close_real'], label='Real 2024', linewidth=2)\n",
    "plt.plot(comp['date'], comp['close_pred'], label='Previsto 2024 (modelo)', linewidth=2, linestyle='--')\n",
    "plt.title('Comparativo: BOVA11 Real vs Previsto (2024)')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Preço de Fechamento')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "# =========================================================\n",
    "# 3️⃣ Exportar resultados para Excel\n",
    "# =========================================================\n",
    "OUT_PATH = os.path.join(BASE_DIR, \"avaliacao_2024_ridge.xlsx\")\n",
    "with pd.ExcelWriter(OUT_PATH, engine='xlsxwriter') as w:\n",
    "   comp.to_excel(w, index=False, sheet_name='comparativo')\n",
    "   pd.DataFrame([{'MAE':mae, 'RMSE':rmse, 'R2':r2}]).to_excel(w, index=False, sheet_name='metricas')\n",
    "print(f\"\\n✅ Avaliação salva em:\\n{OUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64d2555c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linhas histórico (<=2023-12): 48\n",
      "Linhas 2024 (se houver no CSV): 0\n",
      "Linhas após dropna (treino): 47\n",
      "\n",
      "Ridge  | (Histórico 2020–2023)  MAE=1.910  RMSE=2.494  R²=0.875  best={'m__alpha': 0.1}\n",
      "\n",
      "✅ Arquivo gerado em:\n",
      "C:\\Users\\kinagaki\\OneDrive - Digicorner\\Desktop\\Trabalho de Conclusão de Curso - UFRJ.2025\\Correção\\versão atualizada\\TESTE BOVA 11\\bova11_pred_2024_ridge.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "# =========================================================\n",
    "# 1) Caminhos / leitura\n",
    "# =========================================================\n",
    "INPUT_PATH = r\"C:\\Users\\kinagaki\\OneDrive - Digicorner\\Desktop\\Trabalho de Conclusão de Curso - UFRJ.2025\\Correção\\versão atualizada\\TESTE BOVA 11\\bova11_ate_2023.csv\"\n",
    "BASE_DIR   = os.path.dirname(INPUT_PATH)\n",
    "OUTPUT_PATH = os.path.join(BASE_DIR, \"bova11_pred_2024_ridge.xlsx\")\n",
    "df = pd.read_csv(INPUT_PATH, sep=\";\", decimal=\",\", thousands=\".\")\n",
    "# =========================================================\n",
    "# 2) Padronização de colunas / tipos\n",
    "# =========================================================\n",
    "df.columns = (df.columns\n",
    "               .str.strip()\n",
    "               .str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "               .str.lower())\n",
    "rename_map = {\n",
    "   'data': 'date',\n",
    "   'ultimo': 'close', 'último': 'close',\n",
    "   'retorno_mensal_(%)': 'ret_m', 'retorno_mensal': 'ret_m',\n",
    "   'média_móvel_3m': 'mm3', 'media_movel_3m': 'mm3',\n",
    "   'média_móvel_6m': 'mm6', 'media_movel_6m': 'mm6',\n",
    "   'média_móvel_12m': 'mm12','media_movel_12m': 'mm12',\n",
    "   'volatilidade_3m': 'vol3', 'vol3': 'vol3',\n",
    "   'volatilidade_6m': 'vol6', 'vol6': 'vol6',\n",
    "   'momentum': 'momentum3', 'momentum3': 'momentum3',\n",
    "   'volume_relativo': 'volrel', 'volrel': 'volrel',\n",
    "   'close_plus1': 'close_plus1', 'close_+1': 'close_plus1'\n",
    "}\n",
    "df = df.rename(columns={k:v for k,v in rename_map.items() if k in df.columns})\n",
    "df['date'] = pd.to_datetime(df['date'], dayfirst=True, errors='coerce')\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "num_cols = ['close','ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel','close_plus1']\n",
    "for c in num_cols:\n",
    "   if c in df.columns:\n",
    "       df[c] = (df[c].astype(str)\n",
    "                      .str.replace('\\u00A0','',regex=False)\n",
    "                      .str.replace('%','',regex=False)\n",
    "                      .str.replace(' ','',regex=False))\n",
    "       df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "# =========================================================\n",
    "# 3) Separar histórico (até 2023-12) e, opcionalmente, reais de 2024\n",
    "#    -> Treino usa SOMENTE df_hist (sem qualquer 2024)\n",
    "# =========================================================\n",
    "limite_hist = pd.Timestamp('2023-12-01')  # 1º dia de dez/2023\n",
    "df_hist = df[df['date'] <= limite_hist].copy()\n",
    "df_2024 = df[(df['date'] >= pd.Timestamp('2024-01-01')) & (df['date'] <= pd.Timestamp('2024-12-31'))][['date','close']].copy()\n",
    "df_2024.rename(columns={'close':'close_real'}, inplace=True)\n",
    "# Se sua base é “até 2023”, a assert abaixo garante que a última linha é a que vamos prever (jan/24)\n",
    "if 'close_plus1' in df_hist.columns:\n",
    "   assert pd.isna(df_hist.loc[len(df_hist)-1, 'close_plus1']), \"A última linha de 2023 deve estar vazia em close_plus1 (alvo desconhecido).\"\n",
    "print(\"Linhas histórico (<=2023-12):\", len(df_hist))\n",
    "print(\"Linhas 2024 (se houver no CSV):\", len(df_2024))\n",
    "# =========================================================\n",
    "# 4) Treino (Ridge) com validação temporal (somente 2020–2023)\n",
    "# =========================================================\n",
    "FEATS  = ['ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel']\n",
    "TARGET = 'close_plus1'\n",
    "train = df_hist.dropna(subset=FEATS + [TARGET]).copy()\n",
    "print(\"Linhas após dropna (treino):\", len(train))\n",
    "assert len(train) >= 12, \"Poucos dados após limpeza.\"\n",
    "X = train[FEATS].values\n",
    "y = train[TARGET].values\n",
    "tscv  = TimeSeriesSplit(n_splits=5)\n",
    "ridge = Pipeline([('scaler', StandardScaler()), ('m', Ridge())])\n",
    "grid  = {'m__alpha': [0.1, 0.5, 1.0, 2.0, 5.0]}\n",
    "g = GridSearchCV(ridge, grid, cv=tscv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "g.fit(X, y)\n",
    "best_ridge = g.best_estimator_\n",
    "# OOF com máscara (métricas apenas no histórico)\n",
    "y_oof = np.full_like(y, np.nan, dtype=float)\n",
    "for tr, te in tscv.split(X):\n",
    "   best_ridge.fit(X[tr], y[tr])\n",
    "   y_oof[te] = best_ridge.predict(X[te])\n",
    "mask = ~np.isnan(y_oof)\n",
    "mae  = mean_absolute_error(y[mask], y_oof[mask])\n",
    "mse  = mean_squared_error(y[mask], y_oof[mask])\n",
    "rmse = np.sqrt(mse)\n",
    "r2   = r2_score(y[mask], y_oof[mask])\n",
    "print(f\"\\nRidge  | (Histórico 2020–2023)  MAE={mae:.3f}  RMSE={rmse:.3f}  R²={r2:.3f}  best={g.best_params_}\")\n",
    "# =========================================================\n",
    "# 5) Projeção recursiva: gerar exatamente 12 datas de 2024 (sem usar 2024 real)\n",
    "# =========================================================\n",
    "def roll_mean(a,n): return np.mean(a[-n:]) if len(a)>=n else np.nan\n",
    "def roll_std(a,n):  return np.std(a[-n:], ddof=1) if len(a)>=n else np.nan\n",
    "# base de trabalho começa no histórico (até 2023-12)\n",
    "work = df_hist[['date','close','ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel']].copy()\n",
    "volrel_last3 = work['volrel'].tail(3).mean()\n",
    "last_close   = work['close'].iloc[-1]\n",
    "alvos_2024 = pd.date_range('2024-01-01', '2024-12-01', freq='MS')  # 12 meses fixos\n",
    "rows = []\n",
    "for next_date in alvos_2024:\n",
    "   feats_now = work.iloc[-1][FEATS].to_dict()\n",
    "   feats_now['volrel'] = volrel_last3  # hipótese para o mês seguinte\n",
    "   x = np.array([feats_now[f] for f in FEATS], dtype=float).reshape(1, -1)\n",
    "   pred_close_next = float(best_ridge.predict(x)[0])\n",
    "   ret_next  = (pred_close_next / last_close) - 1.0\n",
    "   # anexa linha prevista\n",
    "   work = pd.concat([work, pd.DataFrame([{\n",
    "       'date': next_date, 'close': pred_close_next, 'ret_m': ret_next, 'volrel': volrel_last3\n",
    "   }])], ignore_index=True)\n",
    "   # recalcula features na nova última linha\n",
    "   closes = work['close'].values\n",
    "   rets   = work['ret_m'].values\n",
    "   work.loc[work.index[-1], 'mm3']  = roll_mean(closes, 3)\n",
    "   work.loc[work.index[-1], 'mm6']  = roll_mean(closes, 6)\n",
    "   work.loc[work.index[-1], 'mm12'] = roll_mean(closes,12)\n",
    "   work.loc[work.index[-1], 'vol3'] = roll_std(rets, 3)\n",
    "   work.loc[work.index[-1], 'vol6'] = roll_std(rets, 6)\n",
    "   if len(closes) >= 4:\n",
    "       work.loc[work.index[-1], 'momentum3'] = (closes[-1]/closes[-4]) - 1\n",
    "   last_close = pred_close_next\n",
    "   rows.append({'date': next_date, 'close_pred': pred_close_next})\n",
    "pred_2024 = pd.DataFrame(rows).sort_values('date').reset_index(drop=True)\n",
    "# =========================================================\n",
    "# 6) (Opcional) Avaliar contra reais de 2024, se existirem no CSV\n",
    "#     -> NÃO são usados no treino; apenas comparação em holdout\n",
    "# =========================================================\n",
    "avaliacao_2024 = None\n",
    "if len(df_2024) > 0:\n",
    "   avaliacao_2024 = pred_2024.merge(df_2024, on='date', how='left')\n",
    "   if 'close_real' in avaliacao_2024.columns and avaliacao_2024['close_real'].notna().any():\n",
    "       avaliacao_2024['erro_abs'] = (avaliacao_2024['close_pred'] - avaliacao_2024['close_real']).abs()\n",
    "       avaliacao_2024['erro_%']   = (avaliacao_2024['close_pred'] / avaliacao_2024['close_real'] - 1.0) * 100\n",
    "       mae_24  = avaliacao_2024['erro_abs'].mean(skipna=True)\n",
    "       rmse_24 = np.sqrt(((avaliacao_2024['close_pred'] - avaliacao_2024['close_real'])**2).mean(skipna=True))\n",
    "       print(f\"\\n(Comparação holdout 2024) MAE={mae_24:.3f}  RMSE={rmse_24:.3f}  (onde houver real)\")\n",
    "   else:\n",
    "       print(\"\\nSem closes reais de 2024 no CSV; apenas previsões foram geradas.\")\n",
    "# =========================================================\n",
    "# 7) Salvar Excel no mesmo diretório do CSV\n",
    "# =========================================================\n",
    "try:\n",
    "   with pd.ExcelWriter(OUTPUT_PATH, engine='xlsxwriter') as w:\n",
    "       pred_2024.to_excel(w, index=False, sheet_name='predicoes_2024')  # só 2024\n",
    "       pd.DataFrame([{'MAE_hist':mae,'RMSE_hist':rmse,'R2_hist':r2, **g.best_params_}]).to_excel(w, index=False, sheet_name='metricas_hist')\n",
    "       if avaliacao_2024 is not None:\n",
    "           avaliacao_2024.to_excel(w, index=False, sheet_name='avaliacao_2024')\n",
    "except Exception:\n",
    "   with pd.ExcelWriter(OUTPUT_PATH, engine='openpyxl') as w:\n",
    "       pred_2024.to_excel(w, index=False, sheet_name='predicoes_2024')\n",
    "       pd.DataFrame([{'MAE_hist':mae,'RMSE_hist':rmse,'R2_hist':r2, **g.best_params_}]).to_excel(w, index=False, sheet_name='metricas_hist')\n",
    "       if avaliacao_2024 is not None:\n",
    "           avaliacao_2024.to_excel(w, index=False, sheet_name='avaliacao_2024')\n",
    "print(f\"\\n✅ Arquivo gerado em:\\n{OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56e30213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linhas histórico (<=2023-12): 48\n",
      "Linhas 2024 (se houver no CSV): 0\n",
      "Linhas após dropna (treino): 47\n",
      "\n",
      "Ridge | (Histórico 2020–2023) MAE=1.910 RMSE=2.494 R²=0.875 best={'m__alpha': 0.1}\n",
      "\n",
      "✅ Arquivo gerado com sucesso em:\n",
      "C:\\Users\\kinagaki\\OneDrive - Digicorner\\Desktop\\Trabalho de Conclusão de Curso - UFRJ.2025\\Correção\\versão atualizada\\TESTE BOVA 11\\bova11_pred_2024_ridge.xlsx\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# 1) IMPORTS\n",
    "# =========================================================\n",
    "import os\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "# =========================================================\n",
    "# 2) CAMINHOS / LEITURA\n",
    "# =========================================================\n",
    "INPUT_PATH = r\"C:\\Users\\kinagaki\\OneDrive - Digicorner\\Desktop\\Trabalho de Conclusão de Curso - UFRJ.2025\\Correção\\versão atualizada\\TESTE BOVA 11\\bova11_ate_2023.csv\"\n",
    "BASE_DIR = os.path.dirname(INPUT_PATH)\n",
    "OUTPUT_PATH = os.path.join(BASE_DIR, \"bova11_pred_2024_ridge.xlsx\")\n",
    "df = pd.read_csv(INPUT_PATH, sep=\";\", decimal=\",\", thousands=\".\")\n",
    "# =========================================================\n",
    "# 3) PADRONIZAÇÃO DE COLUNAS / TIPOS\n",
    "# =========================================================\n",
    "df.columns = (df.columns\n",
    "   .str.strip()\n",
    "   .str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "   .str.lower()\n",
    ")\n",
    "rename_map = {\n",
    "   'data': 'date',\n",
    "   'ultimo': 'close', 'último': 'close',\n",
    "   'retorno_mensal_(%)': 'ret_m', 'retorno_mensal': 'ret_m',\n",
    "   'média_móvel_3m': 'mm3', 'media_movel_3m': 'mm3',\n",
    "   'média_móvel_6m': 'mm6', 'media_movel_6m': 'mm6',\n",
    "   'média_móvel_12m': 'mm12','media_movel_12m': 'mm12',\n",
    "   'volatilidade_3m': 'vol3', 'vol3': 'vol3',\n",
    "   'volatilidade_6m': 'vol6', 'vol6': 'vol6',\n",
    "   'momentum': 'momentum3', 'momentum3': 'momentum3',\n",
    "   'volume_relativo': 'volrel', 'volrel': 'volrel',\n",
    "   'close_plus1': 'close_plus1', 'close_+1': 'close_plus1'\n",
    "}\n",
    "df = df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns})\n",
    "df['date'] = pd.to_datetime(df['date'], dayfirst=True, errors='coerce')\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "num_cols = ['close','ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel','close_plus1']\n",
    "for c in num_cols:\n",
    "   if c in df.columns:\n",
    "       df[c] = (df[c].astype(str)\n",
    "                       .str.replace('\\u00A0','',regex=False)\n",
    "                       .str.replace('%','',regex=False)\n",
    "                       .str.replace(' ','',regex=False))\n",
    "       df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "# =========================================================\n",
    "# 4) TRATAMENTO CASO close_plus1 NÃO EXISTA\n",
    "# =========================================================\n",
    "if 'close_plus1' not in df.columns:\n",
    "   df['close_plus1'] = df['close'].shift(-1)\n",
    "# =========================================================\n",
    "# 5) SEPARAR HISTÓRICO (até 2023-12) e REAIS DE 2024 (se houver)\n",
    "# =========================================================\n",
    "limite_hist = pd.Timestamp('2023-12-01')\n",
    "df_hist = df[df['date'] <= limite_hist].copy()\n",
    "df_2024 = df[(df['date'] >= pd.Timestamp('2024-01-01')) & (df['date'] <= pd.Timestamp('2024-12-31'))][['date','close']].copy()\n",
    "df_2024.rename(columns={'close':'close_real'}, inplace=True)\n",
    "if 'close_plus1' in df_hist.columns:\n",
    "   assert pd.isna(df_hist.loc[len(df_hist)-1, 'close_plus1']), \\\n",
    "       \"A última linha de 2023 deve estar vazia em close_plus1 (alvo desconhecido).\"\n",
    "print(\"Linhas histórico (<=2023-12):\", len(df_hist))\n",
    "print(\"Linhas 2024 (se houver no CSV):\", len(df_2024))\n",
    "# =========================================================\n",
    "# 6) TREINO (RIDGE) COM VALIDAÇÃO TEMPORAL\n",
    "# =========================================================\n",
    "FEATS = ['ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel']\n",
    "TARGET = 'close_plus1'\n",
    "train = df_hist.dropna(subset=FEATS + [TARGET]).copy()\n",
    "print(\"Linhas após dropna (treino):\", len(train))\n",
    "assert len(train) >= 12, \"Poucos dados após limpeza.\"\n",
    "X = train[FEATS].values\n",
    "y = train[TARGET].values\n",
    "ridge = Pipeline([('scaler', StandardScaler()), ('m', Ridge())])\n",
    "grid  = {'m__alpha': [0.1, 0.5, 1.0, 2.0, 5.0]}\n",
    "tscv  = TimeSeriesSplit(n_splits=5)\n",
    "g = GridSearchCV(ridge, grid, cv=tscv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "g.fit(X, y)\n",
    "best_ridge = g.best_estimator_\n",
    "# =========================================================\n",
    "# 7) OUT-OF-FOLD MÉTRICAS (HISTÓRICO)\n",
    "# =========================================================\n",
    "y_oof = np.full_like(y, np.nan, dtype=float)\n",
    "for tr, te in tscv.split(X):\n",
    "   best_ridge.fit(X[tr], y[tr])\n",
    "   y_oof[te] = best_ridge.predict(X[te])\n",
    "mask = ~np.isnan(y_oof)\n",
    "mae  = mean_absolute_error(y[mask], y_oof[mask])\n",
    "mse  = mean_squared_error(y[mask], y_oof[mask])\n",
    "rmse = np.sqrt(mse)\n",
    "r2   = r2_score(y[mask], y_oof[mask])\n",
    "print(f\"\\nRidge | (Histórico 2020–2023) MAE={mae:.3f} RMSE={rmse:.3f} R²={r2:.3f} best={g.best_params_}\")\n",
    "# =========================================================\n",
    "# 8) REFIT NO HISTÓRICO COMPLETO (CORREÇÃO IMPORTANTE)\n",
    "# =========================================================\n",
    "best_ridge.fit(X, y)\n",
    "# =========================================================\n",
    "# 9) PROJEÇÃO RECURSIVA DE 12 MESES (2024)\n",
    "# =========================================================\n",
    "def roll_mean(a,n): return np.mean(a[-n:]) if len(a)>=n else np.nan\n",
    "def roll_std(a,n):  return np.std(a[-n:], ddof=1) if len(a)>=n else np.nan\n",
    "work = df_hist[['date','close','ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel']].copy()\n",
    "volrel_last3 = work['volrel'].tail(3).mean()\n",
    "last_close   = work['close'].iloc[-1]\n",
    "rows = []\n",
    "alvos_2024 = pd.date_range('2024-01-01', '2024-12-01', freq='MS')\n",
    "for next_date in alvos_2024:\n",
    "   feats_now = work.iloc[-1][FEATS].to_dict()\n",
    "   feats_now['volrel'] = volrel_last3\n",
    "   x = np.array([feats_now[f] for f in FEATS], dtype=float).reshape(1, -1)\n",
    "   pred_close_next = float(best_ridge.predict(x)[0])\n",
    "   ret_next  = (pred_close_next / last_close) - 1.0\n",
    "   work = pd.concat([work, pd.DataFrame([{\n",
    "       'date': next_date,\n",
    "       'close': pred_close_next,\n",
    "       'ret_m': ret_next,\n",
    "       'volrel': volrel_last3\n",
    "   }])], ignore_index=True)\n",
    "   closes = work['close'].values\n",
    "   rets   = work['ret_m'].values\n",
    "   work.loc[work.index[-1], 'mm3']  = roll_mean(closes, 3)\n",
    "   work.loc[work.index[-1], 'mm6']  = roll_mean(closes, 6)\n",
    "   work.loc[work.index[-1], 'mm12'] = roll_mean(closes, 12)\n",
    "   work.loc[work.index[-1], 'vol3'] = roll_std(rets, 3)\n",
    "   work.loc[work.index[-1], 'vol6'] = roll_std(rets, 6)\n",
    "   if len(closes) >= 4:\n",
    "       work.loc[work.index[-1], 'momentum3'] = (closes[-1]/closes[-4]) - 1\n",
    "   last_close = pred_close_next\n",
    "   rows.append({'date': next_date, 'close_pred': pred_close_next})\n",
    "pred_2024 = pd.DataFrame(rows).sort_values('date').reset_index(drop=True)\n",
    "# =========================================================\n",
    "# 10) AVALIAÇÃO CONTRA REAIS DE 2024 (SE EXISTIREM)\n",
    "# =========================================================\n",
    "avaliacao_2024 = None\n",
    "if len(df_2024) > 0:\n",
    "   avaliacao_2024 = pred_2024.merge(df_2024, on='date', how='left')\n",
    "   if 'close_real' in avaliacao_2024.columns and avaliacao_2024['close_real'].notna().any():\n",
    "       avaliacao_2024['erro_abs'] = (avaliacao_2024['close_pred'] - avaliacao_2024['close_real']).abs()\n",
    "       avaliacao_2024['erro_%']   = (avaliacao_2024['close_pred'] / avaliacao_2024['close_real'] - 1.0) * 100\n",
    "       mae_24  = avaliacao_2024['erro_abs'].mean(skipna=True)\n",
    "       rmse_24 = np.sqrt(((avaliacao_2024['close_pred'] - avaliacao_2024['close_real'])**2).mean(skipna=True))\n",
    "       print(f\"\\n(Comparação holdout 2024) MAE={mae_24:.3f} RMSE={rmse_24:.3f}\")\n",
    "   else:\n",
    "       print(\"\\nSem closes reais de 2024 no CSV; apenas previsões foram geradas.\")\n",
    "# =========================================================\n",
    "# 11) SALVAR RESULTADOS NO EXCEL\n",
    "# =========================================================\n",
    "try:\n",
    "   with pd.ExcelWriter(OUTPUT_PATH, engine='xlsxwriter') as w:\n",
    "       pred_2024.to_excel(w, index=False, sheet_name='predicoes_2024')\n",
    "       pd.DataFrame([{'MAE_hist': mae, 'RMSE_hist': rmse, 'R2_hist': r2, **g.best_params_}]).to_excel(\n",
    "           w, index=False, sheet_name='metricas_hist')\n",
    "       if avaliacao_2024 is not None:\n",
    "           avaliacao_2024.to_excel(w, index=False, sheet_name='avaliacao_2024')\n",
    "except Exception:\n",
    "   with pd.ExcelWriter(OUTPUT_PATH, engine='openpyxl') as w:\n",
    "       pred_2024.to_excel(w, index=False, sheet_name='predicoes_2024')\n",
    "       pd.DataFrame([{'MAE_hist': mae, 'RMSE_hist': rmse, 'R2_hist': r2, **g.best_params_}]).to_excel(\n",
    "           w, index=False, sheet_name='metricas_hist')\n",
    "       if avaliacao_2024 is not None:\n",
    "           avaliacao_2024.to_excel(w, index=False, sheet_name='avaliacao_2024')\n",
    "print(f\"\\n✅ Arquivo gerado com sucesso em:\\n{OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0645a2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linhas histórico (<=2023-12): 48\n",
      "Linhas 2024 (se houver no CSV): 0\n",
      "Linhas após dropna (treino): 47\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "got an unexpected keyword argument 'squared'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 103>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    101\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mnp\u001b[38;5;241m.\u001b[39misnan(y_oof)\n\u001b[0;32m    102\u001b[0m mae  \u001b[38;5;241m=\u001b[39m mean_absolute_error(y[mask], y_oof[mask])\n\u001b[1;32m--> 103\u001b[0m rmse \u001b[38;5;241m=\u001b[39m \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_oof\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m r2   \u001b[38;5;241m=\u001b[39m r2_score(y[mask], y_oof[mask])\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRIDGE (com macro) | MAE=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmae\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m RMSE=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmse\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m R²=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr2\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m best=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mg\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\_param_validation.py:194\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    191\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n\u001b[1;32m--> 194\u001b[0m params \u001b[38;5;241m=\u001b[39m func_sig\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    195\u001b[0m params\u001b[38;5;241m.\u001b[39mapply_defaults()\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# ignore self/cls and positional/keyword markers\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\inspect.py:3045\u001b[0m, in \u001b[0;36mSignature.bind\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3040\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   3041\u001b[0m     \u001b[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[0;32m   3042\u001b[0m \u001b[38;5;124;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[0;32m   3043\u001b[0m \u001b[38;5;124;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[0;32m   3044\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3045\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\inspect.py:3034\u001b[0m, in \u001b[0;36mSignature._bind\u001b[1;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[0;32m   3032\u001b[0m         arguments[kwargs_param\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m kwargs\n\u001b[0;32m   3033\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3034\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   3035\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgot an unexpected keyword argument \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   3036\u001b[0m                 arg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))))\n\u001b[0;32m   3038\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_arguments_cls(\u001b[38;5;28mself\u001b[39m, arguments)\n",
      "\u001b[1;31mTypeError\u001b[0m: got an unexpected keyword argument 'squared'"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# 📘 PREVISÃO BOVA11 COM REGRESSÃO RIDGE\n",
    "#  - Usa features internas + externas (selic_m, ipca_m)\n",
    "#  - Treino: 2020–2023 | Previsão: jan–dez/2024 sem usar 2024 real\n",
    "# =========================================================\n",
    "import os\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "# ======= CONFIG RÁPIDA =======\n",
    "INPUT_PATH = r\"C:\\Users\\kinagaki\\OneDrive - Digicorner\\Desktop\\Trabalho de Conclusão de Curso - UFRJ.2025\\Correção\\versão atualizada\\TESTE BOVA 11\\bova11_ate_2023.csv\"\n",
    "BASE_DIR   = os.path.dirname(INPUT_PATH)\n",
    "OUTPUT_PATH = os.path.join(BASE_DIR, \"bova11_pred_2024_ridge_macro.xlsx\")\n",
    "# Cenário para 2024 (como preencher selic/ipca no futuro sem usar 2024 real)\n",
    "MACRO_METHOD = \"mean3\"   # opções: \"last\" (último valor), \"mean3\" (média últimos 3), \"mean6\" (média últimos 6)\n",
    "# =========================================================\n",
    "# 1) Leitura e padronização\n",
    "# =========================================================\n",
    "df = pd.read_csv(INPUT_PATH, sep=\";\", decimal=\",\", thousands=\".\")\n",
    "df.columns = (df.columns\n",
    "             .str.strip()\n",
    "             .str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "             .str.lower())\n",
    "rename_map = {\n",
    "   'data': 'date',\n",
    "   'ultimo': 'close', 'último': 'close',\n",
    "   'retorno_mensal_(%)': 'ret_m', 'retorno_mensal': 'ret_m',\n",
    "   'média_móvel_3m': 'mm3', 'media_movel_3m': 'mm3',\n",
    "   'média_móvel_6m': 'mm6', 'media_movel_6m': 'mm6',\n",
    "   'média_móvel_12m': 'mm12', 'media_movel_12m': 'mm12',\n",
    "   'volatilidade_3m': 'vol3', 'vol3': 'vol3',\n",
    "   'volatilidade_6m': 'vol6', 'vol6': 'vol6',\n",
    "   'momentum': 'momentum3', 'momentum3': 'momentum3',\n",
    "   'volume_relativo': 'volrel', 'volrel': 'volrel',\n",
    "   'close_plus1': 'close_plus1', 'close_+1': 'close_plus1',\n",
    "   # nomes alternativos para macro, se vierem diferentes\n",
    "   'selic': 'selic_m', 'selic_%': 'selic_m',\n",
    "   'ipca': 'ipca_m', 'ipca_%': 'ipca_m'\n",
    "}\n",
    "df = df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns})\n",
    "df['date'] = pd.to_datetime(df['date'], dayfirst=True, errors='coerce')\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "# Converte para numérico removendo símbolos comuns\n",
    "num_cols = [\n",
    "   'close','ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel',\n",
    "   'close_plus1','selic_m','ipca_m'\n",
    "]\n",
    "for c in num_cols:\n",
    "   if c in df.columns:\n",
    "       df[c] = (df[c].astype(str)\n",
    "                  .str.replace('\\u00A0','',regex=False)  # espaço não separável\n",
    "                  .str.replace('%','',regex=False)\n",
    "                  .str.replace(' ','',regex=False))\n",
    "       df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "# Se faltar close_plus1, cria via shift(-1)\n",
    "if 'close_plus1' not in df.columns:\n",
    "   df['close_plus1'] = df['close'].shift(-1)\n",
    "# Checa presença das variáveis macro\n",
    "assert 'selic_m' in df.columns, \"Coluna 'selic_m' não encontrada no CSV.\"\n",
    "assert 'ipca_m' in df.columns,  \"Coluna 'ipca_m' não encontrada no CSV.\"\n",
    "# =========================================================\n",
    "# 2) Separa histórico (<= 2023-12) e 2024 real (opcional p/ comparação)\n",
    "# =========================================================\n",
    "limite_hist = pd.Timestamp('2023-12-01')\n",
    "df_hist = df[df['date'] <= limite_hist].copy()\n",
    "df_2024 = df[(df['date'] >= pd.Timestamp('2024-01-01')) &\n",
    "            (df['date'] <= pd.Timestamp('2024-12-31'))][['date','close']].copy()\n",
    "df_2024.rename(columns={'close':'close_real'}, inplace=True)\n",
    "# Última linha do histórico deve ter alvo desconhecido (por segurança, se existir)\n",
    "if 'close_plus1' in df_hist.columns:\n",
    "   assert pd.isna(df_hist.loc[len(df_hist)-1, 'close_plus1']), \\\n",
    "       \"A última linha de 2023 deve estar vazia em close_plus1 (alvo desconhecido).\"\n",
    "print(\"Linhas histórico (<=2023-12):\", len(df_hist))\n",
    "print(\"Linhas 2024 (se houver no CSV):\", len(df_2024))\n",
    "# =========================================================\n",
    "# 3) Treino (Ridge) com validação temporal\n",
    "# =========================================================\n",
    "FEATS_BASE  = ['ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel']\n",
    "FEATS_MACRO = ['selic_m','ipca_m']\n",
    "FEATS       = FEATS_BASE + FEATS_MACRO   # agora incluem as externas\n",
    "TARGET = 'close_plus1'\n",
    "train = df_hist.dropna(subset=FEATS + [TARGET]).copy()\n",
    "print(\"Linhas após dropna (treino):\", len(train))\n",
    "assert len(train) >= 12, \"Poucos dados após limpeza (verifique NaNs em selic_m/ipca_m).\"\n",
    "X = train[FEATS].values\n",
    "y = train[TARGET].values\n",
    "ridge = Pipeline([('scaler', StandardScaler()), ('m', Ridge())])\n",
    "grid  = {'m__alpha': [0.1, 0.5, 1.0, 2.0, 5.0]}\n",
    "tscv  = TimeSeriesSplit(n_splits=5)\n",
    "g = GridSearchCV(ridge, grid, cv=tscv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "g.fit(X, y)\n",
    "best_ridge = g.best_estimator_\n",
    "# Métricas OOF\n",
    "y_oof = np.full_like(y, np.nan, dtype=float)\n",
    "for tr, te in tscv.split(X):\n",
    "   best_ridge.fit(X[tr], y[tr])\n",
    "   y_oof[te] = best_ridge.predict(X[te])\n",
    "mask = ~np.isnan(y_oof)\n",
    "mae  = mean_absolute_error(y[mask], y_oof[mask])\n",
    "rmse = mean_squared_error(y[mask], y_oof[mask], squared=False)\n",
    "r2   = r2_score(y[mask], y_oof[mask])\n",
    "print(f\"\\nRIDGE (com macro) | MAE={mae:.3f} RMSE={rmse:.3f} R²={r2:.3f} best={g.best_params_}\")\n",
    "# Refit no histórico completo\n",
    "best_ridge.fit(X, y)\n",
    "# =========================================================\n",
    "# 4) Projeção recursiva 2024 (preenche selic/ipca conforme cenário escolhido)\n",
    "# =========================================================\n",
    "def roll_mean(a,n): return np.mean(a[-n:]) if len(a)>=n else np.nan\n",
    "def roll_std(a,n):  return np.std(a[-n:], ddof=1) if len(a)>=n else np.nan\n",
    "def macro_future_value(series: pd.Series, method: str):\n",
    "   s = series.dropna().values\n",
    "   if len(s) == 0:\n",
    "       return np.nan\n",
    "   if method == \"last\":\n",
    "       return float(s[-1])\n",
    "   elif method == \"mean3\":\n",
    "       return float(np.mean(s[-3:])) if len(s) >= 3 else float(np.mean(s))\n",
    "   elif method == \"mean6\":\n",
    "       return float(np.mean(s[-6:])) if len(s) >= 6 else float(np.mean(s))\n",
    "   else:\n",
    "       # fallback: último\n",
    "       return float(s[-1])\n",
    "work_cols = ['date','close','ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel','selic_m','ipca_m']\n",
    "work = df_hist[work_cols].copy()\n",
    "# Cenários fixos para 2024\n",
    "selic_future = macro_future_value(work['selic_m'], MACRO_METHOD)\n",
    "ipca_future  = macro_future_value(work['ipca_m'],  MACRO_METHOD)\n",
    "volrel_last3 = work['volrel'].tail(3).mean()\n",
    "last_close   = work['close'].iloc[-1]\n",
    "alvos_2024 = pd.date_range('2024-01-01', '2024-12-01', freq='MS')\n",
    "rows = []\n",
    "for next_date in alvos_2024:\n",
    "   feats_now = work.iloc[-1][FEATS].to_dict()\n",
    "   # Impõe valores \"macro\" futuros conforme cenário (sem usar 2024 real)\n",
    "   feats_now['selic_m'] = selic_future\n",
    "   feats_now['ipca_m']  = ipca_future\n",
    "   # Para volrel também usamos cenário simples (média dos 3 últimos)\n",
    "   feats_now['volrel']  = volrel_last3\n",
    "   # Prever close do próximo mês\n",
    "   x = np.array([feats_now[f] for f in FEATS], dtype=float).reshape(1, -1)\n",
    "   pred_close_next = float(best_ridge.predict(x)[0])\n",
    "   # Atualiza retorno e adiciona linha prevista\n",
    "   ret_next = (pred_close_next / last_close) - 1.0\n",
    "   work = pd.concat([work, pd.DataFrame([{\n",
    "       'date': next_date,\n",
    "       'close': pred_close_next,\n",
    "       'ret_m': ret_next,\n",
    "       'volrel': volrel_last3,\n",
    "       'selic_m': selic_future,\n",
    "       'ipca_m':  ipca_future\n",
    "   }])], ignore_index=True)\n",
    "   # Recalcula features de média/vol/ momentum\n",
    "   closes = work['close'].values\n",
    "   rets   = work['ret_m'].values\n",
    "   work.loc[work.index[-1], 'mm3']  = roll_mean(closes, 3)\n",
    "   work.loc[work.index[-1], 'mm6']  = roll_mean(closes, 6)\n",
    "   work.loc[work.index[-1], 'mm12'] = roll_mean(closes,12)\n",
    "   work.loc[work.index[-1], 'vol3'] = roll_std(rets, 3)\n",
    "   work.loc[work.index[-1], 'vol6'] = roll_std(rets, 6)\n",
    "   if len(closes) >= 4:\n",
    "       work.loc[work.index[-1], 'momentum3'] = (closes[-1] / closes[-4]) - 1\n",
    "   last_close = pred_close_next\n",
    "   rows.append({'date': next_date, 'close_pred': pred_close_next})\n",
    "pred_2024 = pd.DataFrame(rows).sort_values('date').reset_index(drop=True)\n",
    "# =========================================================\n",
    "# 5) (Opcional) Comparar com closes reais de 2024 (se estiverem no CSV)\n",
    "# =========================================================\n",
    "avaliacao_2024 = None\n",
    "if len(df_2024) > 0:\n",
    "   avaliacao_2024 = pred_2024.merge(df_2024, on='date', how='left')\n",
    "   if 'close_real' in avaliacao_2024.columns and avaliacao_2024['close_real'].notna().any():\n",
    "       avaliacao_2024['erro_abs'] = (avaliacao_2024['close_pred'] - avaliacao_2024['close_real']).abs()\n",
    "       avaliacao_2024['erro_%']   = (avaliacao_2024['close_pred'] / avaliacao_2024['close_real'] - 1.0) * 100\n",
    "       mae_24  = avaliacao_2024['erro_abs'].mean(skipna=True)\n",
    "       rmse_24 = np.sqrt(((avaliacao_2024['close_pred'] - avaliacao_2024['close_real'])**2).mean(skipna=True))\n",
    "       print(f\"\\n(Comparação holdout 2024) MAE={mae_24:.3f} RMSE={rmse_24:.3f}\")\n",
    "   else:\n",
    "       print(\"\\nSem closes reais de 2024 no CSV; apenas previsões foram geradas.\")\n",
    "# =========================================================\n",
    "# 6) Exporta para Excel (mesmo diretório do CSV)\n",
    "# =========================================================\n",
    "with pd.ExcelWriter(OUTPUT_PATH, engine='xlsxwriter') as w:\n",
    "   # Previsões 2024\n",
    "   pred_2024.to_excel(w, index=False, sheet_name='predicoes_2024')\n",
    "   # Métricas do histórico\n",
    "   pd.DataFrame([{\n",
    "       'MAE_hist': mae, 'RMSE_hist': rmse, 'R2_hist': r2, **g.best_params_\n",
    "   }]).to_excel(w, index=False, sheet_name='metricas_hist')\n",
    "   # Avaliação 2024 (se houver real)\n",
    "   if avaliacao_2024 is not None:\n",
    "       avaliacao_2024.to_excel(w, index=False, sheet_name='avaliacao_2024')\n",
    "   # Documentação do cenário usado para macro\n",
    "   doc = pd.DataFrame([{\n",
    "       'cenario_macro': MACRO_METHOD,\n",
    "       'selic_2024_usada': selic_future,\n",
    "       'ipca_2024_usado': ipca_future,\n",
    "       'volrel_2024_usado': float(volrel_last3)\n",
    "   }])\n",
    "   doc.to_excel(w, index=False, sheet_name='cenario_macro_2024')\n",
    "print(f\"\\n✅ Arquivo gerado com sucesso em:\\n{OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "239d7cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linhas histórico (<=2023-12): 48\n",
      "Linhas 2024 (se houver no CSV): 0\n",
      "Linhas após dropna (treino): 47\n",
      "\n",
      "Ridge | (Histórico 2020–2023) MAE=1.771 RMSE=2.149 R²=0.907 best={'m__alpha': 1.0}\n",
      "\n",
      "✅ Arquivo gerado com sucesso em:\n",
      "C:\\Users\\kinagaki\\OneDrive - Digicorner\\Desktop\\Trabalho de Conclusão de Curso - UFRJ.2025\\Correção\\versão atualizada\\TESTE BOVA 11\\bova11_pred_2024_ridge.xlsx\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# 1) IMPORTS\n",
    "# =========================================================\n",
    "import os\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "# =========================================================\n",
    "# 2) CAMINHOS / LEITURA\n",
    "# =========================================================\n",
    "INPUT_PATH = r\"C:\\Users\\kinagaki\\OneDrive - Digicorner\\Desktop\\Trabalho de Conclusão de Curso - UFRJ.2025\\Correção\\versão atualizada\\TESTE BOVA 11\\bova11_ate_2023.csv\"\n",
    "BASE_DIR = os.path.dirname(INPUT_PATH)\n",
    "OUTPUT_PATH = os.path.join(BASE_DIR, \"bova11_pred_2024_ridge.xlsx\")\n",
    "df = pd.read_csv(INPUT_PATH, sep=\";\", decimal=\",\", thousands=\".\")\n",
    "# =========================================================\n",
    "# 3) PADRONIZAÇÃO DE COLUNAS / TIPOS\n",
    "# =========================================================\n",
    "df.columns = (df.columns\n",
    "  .str.strip()\n",
    "  .str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "  .str.lower()\n",
    ")\n",
    "rename_map = {\n",
    "  'data': 'date',\n",
    "  'ultimo': 'close', 'último': 'close',\n",
    "  'retorno_mensal_(%)': 'ret_m', 'retorno_mensal': 'ret_m',\n",
    "  'média_móvel_3m': 'mm3', 'media_movel_3m': 'mm3',\n",
    "  'média_móvel_6m': 'mm6', 'media_movel_6m': 'mm6',\n",
    "  'média_móvel_12m': 'mm12','media_movel_12m': 'mm12',\n",
    "  'volatilidade_3m': 'vol3', 'vol3': 'vol3',\n",
    "  'volatilidade_6m': 'vol6', 'vol6': 'vol6',\n",
    "  'momentum': 'momentum3', 'momentum3': 'momentum3',\n",
    "  'volume_relativo': 'volrel', 'volrel': 'volrel',\n",
    "  'close_plus1': 'close_plus1', 'close_+1': 'close_plus1'\n",
    "}\n",
    "df = df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns})\n",
    "# >>>>>>> ADIÇÃO: garante que existam as colunas macro selic_m e ipca_m <<<<<<<\n",
    "# (Se já existirem com esses nomes, nada muda)\n",
    "# Caso venham com %, vírgula etc., o tratamento abaixo limpa.\n",
    "df['date'] = pd.to_datetime(df['date'], dayfirst=True, errors='coerce')\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "num_cols = [\n",
    "   'close','ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel',\n",
    "   'close_plus1','selic_m','ipca_m'   # << ADIÇÃO\n",
    "]\n",
    "for c in num_cols:\n",
    "  if c in df.columns:\n",
    "      df[c] = (df[c].astype(str)\n",
    "                      .str.replace('\\u00A0','',regex=False)\n",
    "                      .str.replace('%','',regex=False)\n",
    "                      .str.replace(' ','',regex=False))\n",
    "      df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "# =========================================================\n",
    "# 4) TRATAMENTO CASO close_plus1 NÃO EXISTA\n",
    "# =========================================================\n",
    "if 'close_plus1' not in df.columns:\n",
    "  df['close_plus1'] = df['close'].shift(-1)\n",
    "# =========================================================\n",
    "# 5) SEPARAR HISTÓRICO (até 2023-12) e REAIS DE 2024 (se houver)\n",
    "# =========================================================\n",
    "limite_hist = pd.Timestamp('2023-12-01')\n",
    "df_hist = df[df['date'] <= limite_hist].copy()\n",
    "df_2024 = df[(df['date'] >= pd.Timestamp('2024-01-01')) & (df['date'] <= pd.Timestamp('2024-12-31'))][['date','close']].copy()\n",
    "df_2024.rename(columns={'close':'close_real'}, inplace=True)\n",
    "# Segurança: última linha de 2023 sem alvo conhecido\n",
    "if 'close_plus1' in df_hist.columns:\n",
    "  assert pd.isna(df_hist.loc[len(df_hist)-1, 'close_plus1']), \\\n",
    "      \"A última linha de 2023 deve estar vazia em close_plus1 (alvo desconhecido).\"\n",
    "print(\"Linhas histórico (<=2023-12):\", len(df_hist))\n",
    "print(\"Linhas 2024 (se houver no CSV):\", len(df_2024))\n",
    "# =========================================================\n",
    "# 6) TREINO (RIDGE) COM VALIDAÇÃO TEMPORAL\n",
    "# =========================================================\n",
    "# >>>>>>> ADIÇÃO: inclui selic_m e ipca_m nas features <<<<<<<\n",
    "FEATS = ['ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel','selic_m','ipca_m']\n",
    "TARGET = 'close_plus1'\n",
    "train = df_hist.dropna(subset=FEATS + [TARGET]).copy()\n",
    "print(\"Linhas após dropna (treino):\", len(train))\n",
    "assert len(train) >= 12, \"Poucos dados após limpeza (verifique NaNs em selic_m/ipca_m).\"\n",
    "X = train[FEATS].values\n",
    "y = train[TARGET].values\n",
    "ridge = Pipeline([('scaler', StandardScaler()), ('m', Ridge())])\n",
    "grid  = {'m__alpha': [0.1, 0.5, 1.0, 2.0, 5.0]}\n",
    "tscv  = TimeSeriesSplit(n_splits=5)\n",
    "g = GridSearchCV(ridge, grid, cv=tscv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "g.fit(X, y)\n",
    "best_ridge = g.best_estimator_\n",
    "# =========================================================\n",
    "# 7) OUT-OF-FOLD MÉTRICAS (HISTÓRICO)\n",
    "# =========================================================\n",
    "y_oof = np.full_like(y, np.nan, dtype=float)\n",
    "for tr, te in tscv.split(X):\n",
    "  best_ridge.fit(X[tr], y[tr])\n",
    "  y_oof[te] = best_ridge.predict(X[te])\n",
    "mask = ~np.isnan(y_oof)\n",
    "mae  = mean_absolute_error(y[mask], y_oof[mask])\n",
    "mse  = mean_squared_error(y[mask], y_oof[mask])\n",
    "rmse = np.sqrt(mse)\n",
    "r2   = r2_score(y[mask], y_oof[mask])\n",
    "print(f\"\\nRidge | (Histórico 2020–2023) MAE={mae:.3f} RMSE={rmse:.3f} R²={r2:.3f} best={g.best_params_}\")\n",
    "# =========================================================\n",
    "# 8) REFIT NO HISTÓRICO COMPLETO (CORREÇÃO IMPORTANTE)\n",
    "# =========================================================\n",
    "best_ridge.fit(X, y)\n",
    "# =========================================================\n",
    "# 9) PROJEÇÃO RECURSIVA DE 12 MESES (2024)\n",
    "# =========================================================\n",
    "def roll_mean(a,n): return np.mean(a[-n:]) if len(a)>=n else np.nan\n",
    "def roll_std(a,n):  return np.std(a[-n:], ddof=1) if len(a)>=n else np.nan\n",
    "# >>>>>>> ADIÇÃO: manter selic/ipca fixos em 2024 (último valor de 2023) <<<<<<<\n",
    "selic_last = df_hist['selic_m'].dropna().iloc[-1] if 'selic_m' in df_hist.columns else np.nan\n",
    "ipca_last  = df_hist['ipca_m'].dropna().iloc[-1]  if 'ipca_m'  in df_hist.columns else np.nan\n",
    "work = df_hist[['date','close','ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel','selic_m','ipca_m']].copy()\n",
    "volrel_last3 = work['volrel'].tail(3).mean()\n",
    "last_close   = work['close'].iloc[-1]\n",
    "rows = []\n",
    "alvos_2024 = pd.date_range('2024-01-01', '2024-12-01', freq='MS')\n",
    "for next_date in alvos_2024:\n",
    "  feats_now = work.iloc[-1][FEATS].to_dict()\n",
    "  # fixa macro para 2024 (sem usar dados reais de 2024)\n",
    "  feats_now['selic_m'] = selic_last\n",
    "  feats_now['ipca_m']  = ipca_last\n",
    "  # mantém volrel simples (média 3 últimos)\n",
    "  feats_now['volrel']  = volrel_last3\n",
    "  x = np.array([feats_now[f] for f in FEATS], dtype=float).reshape(1, -1)\n",
    "  pred_close_next = float(best_ridge.predict(x)[0])\n",
    "  ret_next = (pred_close_next / last_close) - 1.0\n",
    "  work = pd.concat([work, pd.DataFrame([{\n",
    "      'date': next_date,\n",
    "      'close': pred_close_next,\n",
    "      'ret_m': ret_next,\n",
    "      'volrel': volrel_last3,\n",
    "      'selic_m': selic_last,\n",
    "      'ipca_m': ipca_last\n",
    "  }])], ignore_index=True)\n",
    "  closes = work['close'].values\n",
    "  rets   = work['ret_m'].values\n",
    "  work.loc[work.index[-1], 'mm3']  = roll_mean(closes, 3)\n",
    "  work.loc[work.index[-1], 'mm6']  = roll_mean(closes, 6)\n",
    "  work.loc[work.index[-1], 'mm12'] = roll_mean(closes, 12)\n",
    "  work.loc[work.index[-1], 'vol3'] = roll_std(rets, 3)\n",
    "  work.loc[work.index[-1], 'vol6'] = roll_std(rets, 6)\n",
    "  if len(closes) >= 4:\n",
    "      work.loc[work.index[-1], 'momentum3'] = (closes[-1]/closes[-4]) - 1\n",
    "  last_close = pred_close_next\n",
    "  rows.append({'date': next_date, 'close_pred': pred_close_next})\n",
    "pred_2024 = pd.DataFrame(rows).sort_values('date').reset_index(drop=True)\n",
    "# =========================================================\n",
    "# 10) AVALIAÇÃO CONTRA REAIS DE 2024 (SE EXISTIREM)\n",
    "# =========================================================\n",
    "avaliacao_2024 = None\n",
    "if len(df_2024) > 0:\n",
    "  avaliacao_2024 = pred_2024.merge(df_2024, on='date', how='left')\n",
    "  if 'close_real' in avaliacao_2024.columns and avaliacao_2024['close_real'].notna().any():\n",
    "      avaliacao_2024['erro_abs'] = (avaliacao_2024['close_pred'] - avaliacao_2024['close_real']).abs()\n",
    "      avaliacao_2024['erro_%']   = (avaliacao_2024['close_pred'] / avaliacao_2024['close_real'] - 1.0) * 100\n",
    "      mae_24  = avaliacao_2024['erro_abs'].mean(skipna=True)\n",
    "      rmse_24 = np.sqrt(((avaliacao_2024['close_pred'] - avaliacao_2024['close_real'])**2).mean(skipna=True))\n",
    "      print(f\"\\n(Comparação holdout 2024) MAE={mae_24:.3f} RMSE={rmse_24:.3f}\")\n",
    "  else:\n",
    "      print(\"\\nSem closes reais de 2024 no CSV; apenas previsões foram geradas.\")\n",
    "# =========================================================\n",
    "# 11) SALVAR RESULTADOS NO EXCEL\n",
    "# =========================================================\n",
    "try:\n",
    "  with pd.ExcelWriter(OUTPUT_PATH, engine='xlsxwriter') as w:\n",
    "      pred_2024.to_excel(w, index=False, sheet_name='predicoes_2024')\n",
    "      pd.DataFrame([{'MAE_hist': mae, 'RMSE_hist': rmse, 'R2_hist': r2, **g.best_params_}]).to_excel(\n",
    "          w, index=False, sheet_name='metricas_hist')\n",
    "      if avaliacao_2024 is not None:\n",
    "          avaliacao_2024.to_excel(w, index=False, sheet_name='avaliacao_2024')\n",
    "except Exception:\n",
    "  with pd.ExcelWriter(OUTPUT_PATH, engine='openpyxl') as w:\n",
    "      pred_2024.to_excel(w, index=False, sheet_name='predicoes_2024')\n",
    "      pd.DataFrame([{'MAE_hist': mae, 'RMSE_hist': rmse, 'R2_hist': r2, **g.best_params_}]).to_excel(\n",
    "          w, index=False, sheet_name='metricas_hist')\n",
    "      if avaliacao_2024 is not None:\n",
    "          avaliacao_2024.to_excel(w, index=False, sheet_name='avaliacao_2024')\n",
    "print(f\"\\n✅ Arquivo gerado com sucesso em:\\n{OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7797324",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
