{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf7cb566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linhas histórico (<=2023-12): 48\n",
      "Linhas 2024 (se houver no CSV): 0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "['selic_m', 'ipca_m']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 76>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     73\u001b[0m FEATS \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mret_m\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmm3\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmm6\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmm12\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvol3\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvol6\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     74\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmomentum3\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolrel\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselic_m\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mipca_m\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     75\u001b[0m TARGET \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose_plus1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 76\u001b[0m train \u001b[38;5;241m=\u001b[39m \u001b[43mdf_hist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFEATS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mTARGET\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinhas após dropna (treino):\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(train))\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(train) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPoucos dados após limpeza (verifique NaNs).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:6002\u001b[0m, in \u001b[0;36mDataFrame.dropna\u001b[1;34m(self, axis, how, thresh, subset, inplace)\u001b[0m\n\u001b[0;32m   6000\u001b[0m     check \u001b[38;5;241m=\u001b[39m indices \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   6001\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m-> 6002\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(np\u001b[38;5;241m.\u001b[39marray(subset)[check]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[0;32m   6003\u001b[0m     agg_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indices, axis\u001b[38;5;241m=\u001b[39magg_axis)\n\u001b[0;32m   6005\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m thresh \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: ['selic_m', 'ipca_m']"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# 1) IMPORTS\n",
    "# =========================================================\n",
    "import os\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "# =========================================================\n",
    "# 2) CAMINHOS / LEITURA\n",
    "# =========================================================\n",
    "INPUT_PATH = r\"C:\\Users\\kinagaki\\OneDrive - Digicorner\\Desktop\\Trabalho de Conclusão de Curso - UFRJ.2025\\Correção\\versão atualizada\\TESTE BITCOIN\\bitcoin_ate_2023.csv\"\n",
    "BASE_DIR = os.path.dirname(INPUT_PATH)\n",
    "OUTPUT_PATH = os.path.join(BASE_DIR, \"bitcoin_pred_2024_forest.xlsx\")\n",
    "df = pd.read_csv(INPUT_PATH, sep=\";\", decimal=\",\", thousands=\".\")\n",
    "# =========================================================\n",
    "# 3) PADRONIZAÇÃO DE COLUNAS / TIPOS\n",
    "# =========================================================\n",
    "df.columns = (df.columns\n",
    "  .str.strip()\n",
    "  .str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "  .str.lower()\n",
    ")\n",
    "rename_map = {\n",
    "  'data': 'date',\n",
    "  'ultimo': 'close', 'último': 'close',\n",
    "  'retorno_mensal_(%)': 'ret_m', 'retorno_mensal': 'ret_m',\n",
    "  'média_móvel_3m': 'mm3', 'media_movel_3m': 'mm3',\n",
    "  'média_móvel_6m': 'mm6', 'media_movel_6m': 'mm6',\n",
    "  'média_móvel_12m': 'mm12','media_movel_12m': 'mm12',\n",
    "  'volatilidade_3m': 'vol3', 'vol3': 'vol3',\n",
    "  'volatilidade_6m': 'vol6', 'vol6': 'vol6',\n",
    "  'momentum': 'momentum3', 'momentum3': 'momentum3',\n",
    "  'volume_relativo': 'volrel', 'volrel': 'volrel',\n",
    "  'close_plus1': 'close_plus1', 'close_+1': 'close_plus1'\n",
    "}\n",
    "df = df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns})\n",
    "df['date'] = pd.to_datetime(df['date'], dayfirst=True, errors='coerce')\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "# Conversão numérica das colunas\n",
    "num_cols = [\n",
    "   'close','ret_m','mm3','mm6','mm12','vol3','vol6',\n",
    "   'momentum3','volrel','close_plus1','selic_m','ipca_m'\n",
    "]\n",
    "for c in num_cols:\n",
    "  if c in df.columns:\n",
    "      df[c] = (df[c].astype(str)\n",
    "                      .str.replace('\\u00A0','',regex=False)\n",
    "                      .str.replace('%','',regex=False)\n",
    "                      .str.replace(' ','',regex=False))\n",
    "      df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "# =========================================================\n",
    "# 4) TRATAMENTO CASO close_plus1 NÃO EXISTA\n",
    "# =========================================================\n",
    "if 'close_plus1' not in df.columns:\n",
    "  df['close_plus1'] = df['close'].shift(-1)\n",
    "# =========================================================\n",
    "# 5) SEPARAR HISTÓRICO (até 2023-12) e REAIS DE 2024 (se houver)\n",
    "# =========================================================\n",
    "limite_hist = pd.Timestamp('2023-12-01')\n",
    "df_hist = df[df['date'] <= limite_hist].copy()\n",
    "df_2024 = df[(df['date'] >= pd.Timestamp('2024-01-01')) &\n",
    "            (df['date'] <= pd.Timestamp('2024-12-31'))][['date','close']].copy()\n",
    "df_2024.rename(columns={'close':'close_real'}, inplace=True)\n",
    "if 'close_plus1' in df_hist.columns:\n",
    "  assert pd.isna(df_hist.loc[len(df_hist)-1, 'close_plus1']), \\\n",
    "      \"A última linha de 2023 deve estar vazia em close_plus1 (alvo desconhecido).\"\n",
    "print(\"Linhas histórico (<=2023-12):\", len(df_hist))\n",
    "print(\"Linhas 2024 (se houver no CSV):\", len(df_2024))\n",
    "# =========================================================\n",
    "# 6) TREINO (Random Forest) COM VALIDAÇÃO TEMPORAL\n",
    "# =========================================================\n",
    "FEATS = ['ret_m','mm3','mm6','mm12','vol3','vol6',\n",
    "        'momentum3','volrel','selic_m','ipca_m']\n",
    "TARGET = 'close_plus1'\n",
    "train = df_hist.dropna(subset=FEATS + [TARGET]).copy()\n",
    "print(\"Linhas após dropna (treino):\", len(train))\n",
    "assert len(train) >= 12, \"Poucos dados após limpeza (verifique NaNs).\"\n",
    "X = train[FEATS].values\n",
    "y = train[TARGET].values\n",
    "# Define o modelo e o grid de parâmetros\n",
    "forest = RandomForestRegressor(random_state=42)\n",
    "grid = {\n",
    "   'n_estimators': [100, 200],\n",
    "   'max_depth': [3, 5, 7, 9],\n",
    "   'min_samples_split': [2, 3, 4],\n",
    "   'min_samples_leaf': [1, 2]\n",
    "}\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "g = GridSearchCV(forest, grid, cv=tscv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "g.fit(X, y)\n",
    "best_forest = g.best_estimator_\n",
    "# =========================================================\n",
    "# 7) OUT-OF-FOLD MÉTRICAS (HISTÓRICO)\n",
    "# =========================================================\n",
    "y_oof = np.full_like(y, np.nan, dtype=float)\n",
    "for tr, te in tscv.split(X):\n",
    "  best_forest.fit(X[tr], y[tr])\n",
    "  y_oof[te] = best_forest.predict(X[te])\n",
    "mask = ~np.isnan(y_oof)\n",
    "mae  = mean_absolute_error(y[mask], y_oof[mask])\n",
    "mse  = mean_squared_error(y[mask], y_oof[mask])\n",
    "rmse = np.sqrt(mse)\n",
    "r2   = r2_score(y[mask], y_oof[mask])\n",
    "print(f\"\\nRandomForest | MAE={mae:.3f} RMSE={rmse:.3f} R²={r2:.3f} best={g.best_params_}\")\n",
    "# =========================================================\n",
    "# 8) REFIT NO HISTÓRICO COMPLETO\n",
    "# =========================================================\n",
    "best_forest.fit(X, y)\n",
    "# =========================================================\n",
    "# 9) PROJEÇÃO RECURSIVA DE 12 MESES (2024)\n",
    "# =========================================================\n",
    "def roll_mean(a,n): return np.mean(a[-n:]) if len(a)>=n else np.nan\n",
    "def roll_std(a,n):  return np.std(a[-n:], ddof=1) if len(a)>=n else np.nan\n",
    "selic_last = df_hist['selic_m'].dropna().iloc[-1] if 'selic_m' in df_hist.columns else np.nan\n",
    "ipca_last  = df_hist['ipca_m'].dropna().iloc[-1]  if 'ipca_m'  in df_hist.columns else np.nan\n",
    "work = df_hist[['date','close','ret_m','mm3','mm6','mm12','vol3','vol6',\n",
    "               'momentum3','volrel','selic_m','ipca_m']].copy()\n",
    "volrel_last3 = work['volrel'].tail(3).mean()\n",
    "last_close   = work['close'].iloc[-1]\n",
    "rows = []\n",
    "alvos_2024 = pd.date_range('2024-01-01', '2024-12-01', freq='MS')\n",
    "for next_date in alvos_2024:\n",
    "  feats_now = work.iloc[-1][FEATS].to_dict()\n",
    "  feats_now['selic_m'] = selic_last\n",
    "  feats_now['ipca_m']  = ipca_last\n",
    "  feats_now['volrel']  = volrel_last3\n",
    "  x = np.array([feats_now[f] for f in FEATS], dtype=float).reshape(1, -1)\n",
    "  pred_close_next = float(best_forest.predict(x)[0])\n",
    "  ret_next = (pred_close_next / last_close) - 1.0\n",
    "  work = pd.concat([work, pd.DataFrame([{\n",
    "      'date': next_date,\n",
    "      'close': pred_close_next,\n",
    "      'ret_m': ret_next,\n",
    "      'volrel': volrel_last3,\n",
    "      'selic_m': selic_last,\n",
    "      'ipca_m': ipca_last\n",
    "  }])], ignore_index=True)\n",
    "  closes = work['close'].values\n",
    "  rets   = work['ret_m'].values\n",
    "  work.loc[work.index[-1], 'mm3']  = roll_mean(closes, 3)\n",
    "  work.loc[work.index[-1], 'mm6']  = roll_mean(closes, 6)\n",
    "  work.loc[work.index[-1], 'mm12'] = roll_mean(closes, 12)\n",
    "  work.loc[work.index[-1], 'vol3'] = roll_std(rets, 3)\n",
    "  work.loc[work.index[-1], 'vol6'] = roll_std(rets, 6)\n",
    "  if len(closes) >= 4:\n",
    "      work.loc[work.index[-1], 'momentum3'] = (closes[-1]/closes[-4]) - 1\n",
    "  last_close = pred_close_next\n",
    "  rows.append({'date': next_date, 'close_pred': pred_close_next})\n",
    "pred_2024 = pd.DataFrame(rows).sort_values('date').reset_index(drop=True)\n",
    "# =========================================================\n",
    "# 10) AVALIAÇÃO CONTRA REAIS DE 2024 (SE EXISTIREM)\n",
    "# =========================================================\n",
    "avaliacao_2024 = None\n",
    "if len(df_2024) > 0:\n",
    "  avaliacao_2024 = pred_2024.merge(df_2024, on='date', how='left')\n",
    "  if 'close_real' in avaliacao_2024.columns and avaliacao_2024['close_real'].notna().any():\n",
    "      avaliacao_2024['erro_abs'] = (avaliacao_2024['close_pred'] - avaliacao_2024['close_real']).abs()\n",
    "      avaliacao_2024['erro_%']   = (avaliacao_2024['close_pred'] / avaliacao_2024['close_real'] - 1.0) * 100\n",
    "      mae_24  = avaliacao_2024['erro_abs'].mean(skipna=True)\n",
    "      rmse_24 = np.sqrt(((avaliacao_2024['close_pred'] - avaliacao_2024['close_real'])**2).mean(skipna=True))\n",
    "      print(f\"\\n(Comparação holdout 2024) MAE={mae_24:.3f} RMSE={rmse_24:.3f}\")\n",
    "  else:\n",
    "      print(\"\\nSem closes reais de 2024 no CSV; apenas previsões foram geradas.\")\n",
    "# =========================================================\n",
    "# 11) SALVAR RESULTADOS NO EXCEL\n",
    "# =========================================================\n",
    "try:\n",
    "  with pd.ExcelWriter(OUTPUT_PATH, engine='xlsxwriter') as w:\n",
    "      pred_2024.to_excel(w, index=False, sheet_name='predicoes_2024')\n",
    "      pd.DataFrame([{'MAE_hist': mae, 'RMSE_hist': rmse, 'R2_hist': r2, **g.best_params_}]).to_excel(\n",
    "          w, index=False, sheet_name='metricas_hist')\n",
    "      if avaliacao_2024 is not None:\n",
    "          avaliacao_2024.to_excel(w, index=False, sheet_name='avaliacao_2024')\n",
    "except Exception:\n",
    "  with pd.ExcelWriter(OUTPUT_PATH, engine='openpyxl') as w:\n",
    "      pred_2024.to_excel(w, index=False, sheet_name='predicoes_2024')\n",
    "      pd.DataFrame([{'MAE_hist': mae, 'RMSE_hist': rmse, 'R2_hist': r2, **g.best_params_}]).to_excel(\n",
    "          w, index=False, sheet_name='metricas_hist')\n",
    "      if avaliacao_2024 is not None:\n",
    "          avaliacao_2024.to_excel(w, index=False, sheet_name='avaliacao_2024')\n",
    "print(f\"\\n✅ Arquivo gerado com sucesso em:\\n{OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5546e2f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "got an unexpected keyword argument 'squared'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 67>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mnp\u001b[38;5;241m.\u001b[39misnan(y_oof)\n\u001b[0;32m     66\u001b[0m mae  \u001b[38;5;241m=\u001b[39m mean_absolute_error(y[mask], y_oof[mask])\n\u001b[1;32m---> 67\u001b[0m rmse \u001b[38;5;241m=\u001b[39m \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_oof\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m r2   \u001b[38;5;241m=\u001b[39m r2_score(y[mask], y_oof[mask])\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForest HIST | MAE=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmae\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m RMSE=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmse\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m R²=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr2\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m best=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mg\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\_param_validation.py:194\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    191\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n\u001b[1;32m--> 194\u001b[0m params \u001b[38;5;241m=\u001b[39m func_sig\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    195\u001b[0m params\u001b[38;5;241m.\u001b[39mapply_defaults()\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# ignore self/cls and positional/keyword markers\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\inspect.py:3045\u001b[0m, in \u001b[0;36mSignature.bind\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3040\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   3041\u001b[0m     \u001b[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[0;32m   3042\u001b[0m \u001b[38;5;124;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[0;32m   3043\u001b[0m \u001b[38;5;124;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[0;32m   3044\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3045\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\inspect.py:3034\u001b[0m, in \u001b[0;36mSignature._bind\u001b[1;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[0;32m   3032\u001b[0m         arguments[kwargs_param\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m kwargs\n\u001b[0;32m   3033\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3034\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   3035\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgot an unexpected keyword argument \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   3036\u001b[0m                 arg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))))\n\u001b[0;32m   3038\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_arguments_cls(\u001b[38;5;28mself\u001b[39m, arguments)\n",
      "\u001b[1;31mTypeError\u001b[0m: got an unexpected keyword argument 'squared'"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# RANDOM FOREST – BITCOIN 2024\n",
    "# ==============================\n",
    "import os\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "INPUT_PATH = r\"C:\\Users\\kinagaki\\OneDrive - Digicorner\\Desktop\\Trabalho de Conclusão de Curso - UFRJ.2025\\Correção\\versão atualizada\\TESTE BITCOIN\\bitcoin_ate_2023.csv\"\n",
    "BASE_DIR   = os.path.dirname(INPUT_PATH)\n",
    "OUTPUT_PATH = os.path.join(BASE_DIR, \"bitcoin_pred_2024_forest.xlsx\")\n",
    "df = pd.read_csv(INPUT_PATH, sep=\";\", decimal=\",\", thousands=\".\")\n",
    "df.columns = (df.columns.str.strip()\n",
    "                       .str.replace(r\"\\s+\",\"_\", regex=True)\n",
    "                       .str.lower())\n",
    "rename_map = {\n",
    "   'data':'date','ultimo':'close','último':'close',\n",
    "   'retorno_mensal_(%)':'ret_m','retorno_mensal':'ret_m',\n",
    "   'média_móvel_3m':'mm3','media_movel_3m':'mm3',\n",
    "   'média_móvel_6m':'mm6','media_movel_6m':'mm6',\n",
    "   'média_móvel_12m':'mm12','media_movel_12m':'mm12',\n",
    "   'volatilidade_3m':'vol3','vol3':'vol3',\n",
    "   'volatilidade_6m':'vol6','vol6':'vol6',\n",
    "   'momentum':'momentum3','momentum3':'momentum3',\n",
    "   'volume_relativo':'volrel','volrel':'volrel',\n",
    "   'close_plus1':'close_plus1','close_+1':'close_plus1'\n",
    "}\n",
    "df = df.rename(columns={k:v for k,v in rename_map.items() if k in df.columns})\n",
    "df['date'] = pd.to_datetime(df['date'], dayfirst=True, errors='coerce')\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "num_cols = ['close','ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel','close_plus1']\n",
    "for c in num_cols:\n",
    "   if c in df.columns:\n",
    "       df[c] = (df[c].astype(str).str.replace('\\u00A0','',regex=False)\n",
    "                             .str.replace('%','',regex=False)\n",
    "                             .str.replace(' ','',regex=False))\n",
    "       df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "if 'close_plus1' not in df.columns:\n",
    "   df['close_plus1'] = df['close'].shift(-1)\n",
    "limite_hist = pd.Timestamp('2023-12-01')\n",
    "df_hist = df[df['date'] <= limite_hist].copy()\n",
    "df_2024 = df[(df['date'] >= '2024-01-01') & (df['date'] <= '2024-12-31')][['date','close']].copy().rename(columns={'close':'close_real'})\n",
    "if 'close_plus1' in df_hist.columns:\n",
    "   assert pd.isna(df_hist.loc[len(df_hist)-1,'close_plus1'])\n",
    "FEATS  = ['ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel']\n",
    "TARGET = 'close_plus1'\n",
    "train = df_hist.dropna(subset=FEATS+[TARGET]).copy()\n",
    "X, y = train[FEATS].values, train[TARGET].values\n",
    "forest = RandomForestRegressor(random_state=42)\n",
    "grid = {\n",
    "   'n_estimators':[100,200],\n",
    "   'max_depth':[3,5,7,9],\n",
    "   'min_samples_split':[2,3,4],\n",
    "   'min_samples_leaf':[1,2]\n",
    "}\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "g = GridSearchCV(forest, grid, cv=tscv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "g.fit(X,y)\n",
    "best_forest = g.best_estimator_\n",
    "# OOF\n",
    "y_oof = np.full_like(y, np.nan, dtype=float)\n",
    "for tr,te in tscv.split(X):\n",
    "   best_forest.fit(X[tr], y[tr])\n",
    "   y_oof[te] = best_forest.predict(X[te])\n",
    "mask = ~np.isnan(y_oof)\n",
    "mae  = mean_absolute_error(y[mask], y_oof[mask])\n",
    "rmse = mean_squared_error(y[mask], y_oof[mask], squared=False)\n",
    "r2   = r2_score(y[mask], y_oof[mask])\n",
    "print(f\"Forest HIST | MAE={mae:.3f} RMSE={rmse:.3f} R²={r2:.3f} best={g.best_params_}\")\n",
    "best_forest.fit(X,y)\n",
    "# Projeção recursiva\n",
    "def roll_mean(a,n): return np.mean(a[-n:]) if len(a)>=n else np.nan\n",
    "def roll_std(a,n):  return np.std(a[-n:], ddof=1) if len(a)>=n else np.nan\n",
    "work = df_hist[['date','close','ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel']].copy()\n",
    "volrel_last3 = work['volrel'].tail(3).mean()\n",
    "last_close   = work['close'].iloc[-1]\n",
    "rows = []\n",
    "for next_date in pd.date_range('2024-01-01','2024-12-01',freq='MS'):\n",
    "   feats_now = work.iloc[-1][FEATS].to_dict()\n",
    "   feats_now['volrel'] = volrel_last3\n",
    "   x = np.array([feats_now[f] for f in FEATS], dtype=float).reshape(1,-1)\n",
    "   pred_close_next = float(best_forest.predict(x)[0])\n",
    "   ret_next = (pred_close_next/last_close) - 1.0\n",
    "   work = pd.concat([work, pd.DataFrame([{\n",
    "       'date': next_date, 'close': pred_close_next, 'ret_m': ret_next, 'volrel': volrel_last3\n",
    "   }])], ignore_index=True)\n",
    "   closes = work['close'].values\n",
    "   rets   = work['ret_m'].values\n",
    "   work.loc[work.index[-1],'mm3']  = roll_mean(closes,3)\n",
    "   work.loc[work.index[-1],'mm6']  = roll_mean(closes,6)\n",
    "   work.loc[work.index[-1],'mm12'] = roll_mean(closes,12)\n",
    "   work.loc[work.index[-1],'vol3'] = roll_std(rets,3)\n",
    "   work.loc[work.index[-1],'vol6'] = roll_std(rets,6)\n",
    "   if len(closes)>=4:\n",
    "       work.loc[work.index[-1],'momentum3'] = (closes[-1]/closes[-4]) - 1\n",
    "   last_close = pred_close_next\n",
    "   rows.append({'date': next_date, 'close_pred': pred_close_next})\n",
    "pred_2024 = pd.DataFrame(rows).sort_values('date').reset_index(drop=True)\n",
    "avaliacao_2024 = None\n",
    "if len(df_2024)>0:\n",
    "   avaliacao_2024 = pred_2024.merge(df_2024, on='date', how='left')\n",
    "   if avaliacao_2024['close_real'].notna().any():\n",
    "       avaliacao_2024['erro_abs'] = (avaliacao_2024['close_pred']-avaliacao_2024['close_real']).abs()\n",
    "       avaliacao_2024['erro_%']   = (avaliacao_2024['close_pred']/avaliacao_2024['close_real']-1)*100\n",
    "       mae_24  = avaliacao_2024['erro_abs'].mean(skipna=True)\n",
    "       rmse_24 = np.sqrt(((avaliacao_2024['close_pred']-avaliacao_2024['close_real'])**2).mean(skipna=True))\n",
    "       print(f\"(Holdout 2024) MAE={mae_24:.3f} RMSE={rmse_24:.3f}\")\n",
    "try:\n",
    "   with pd.ExcelWriter(OUTPUT_PATH, engine='xlsxwriter') as w:\n",
    "       pred_2024.to_excel(w, index=False, sheet_name='predicoes_2024')\n",
    "       pd.DataFrame([{'MAE_hist':mae,'RMSE_hist':rmse,'R2_hist':r2, **g.best_params_}]).to_excel(\n",
    "           w, index=False, sheet_name='metricas_hist')\n",
    "       if avaliacao_2024 is not None:\n",
    "           avaliacao_2024.to_excel(w, index=False, sheet_name='avaliacao_2024')\n",
    "except Exception:\n",
    "   with pd.ExcelWriter(OUTPUT_PATH, engine='openpyxl') as w:\n",
    "       pred_2024.to_excel(w, index=False, sheet_name='predicoes_2024')\n",
    "       pd.DataFrame([{'MAE_hist':mae,'RMSE_hist':rmse,'R2_hist':r2, **g.best_params_}]).to_excel(\n",
    "           w, index=False, sheet_name='metricas_hist')\n",
    "       if avaliacao_2024 is not None:\n",
    "           avaliacao_2024.to_excel(w, index=False, sheet_name='avaliacao_2024')\n",
    "print(f\"✅ Arquivo gerado em:\\n{OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b965717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linhas histórico (<=2023-12): 48\n",
      "Linhas 2024 (se houver no CSV): 0\n",
      "Linhas após dropna (treino): 47\n",
      "\n",
      "RandomForest | MAE=10971.123 RMSE=15376.446 R²=-0.565 best={'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "\n",
      "✅ Arquivo gerado com sucesso em:\n",
      "C:\\Users\\kinagaki\\OneDrive - Digicorner\\Desktop\\Trabalho de Conclusão de Curso - UFRJ.2025\\Correção\\versão atualizada\\TESTE BITCOIN\\bitcoin_pred_2024_forest.xlsx\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# 1) IMPORTS\n",
    "# =========================================================\n",
    "import os\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "# =========================================================\n",
    "# 2) CAMINHOS / LEITURA\n",
    "# =========================================================\n",
    "INPUT_PATH = r\"C:\\Users\\kinagaki\\OneDrive - Digicorner\\Desktop\\Trabalho de Conclusão de Curso - UFRJ.2025\\Correção\\versão atualizada\\TESTE BITCOIN\\bitcoin_ate_2023.csv\"\n",
    "BASE_DIR = os.path.dirname(INPUT_PATH)\n",
    "OUTPUT_PATH = os.path.join(BASE_DIR, \"bitcoin_pred_2024_forest.xlsx\")\n",
    "df = pd.read_csv(INPUT_PATH, sep=\";\", decimal=\",\", thousands=\".\")\n",
    "# =========================================================\n",
    "# 3) PADRONIZAÇÃO DE COLUNAS / TIPOS\n",
    "# =========================================================\n",
    "df.columns = (df.columns\n",
    " .str.strip()\n",
    " .str.replace(r\"\\s+\", \"_\", regex=True)\n",
    " .str.lower()\n",
    ")\n",
    "rename_map = {\n",
    " 'data': 'date',\n",
    " 'ultimo': 'close', 'último': 'close',\n",
    " 'retorno_mensal_(%)': 'ret_m', 'retorno_mensal': 'ret_m',\n",
    " 'média_móvel_3m': 'mm3', 'media_movel_3m': 'mm3',\n",
    " 'média_móvel_6m': 'mm6', 'media_movel_6m': 'mm6',\n",
    " 'média_móvel_12m': 'mm12','media_movel_12m': 'mm12',\n",
    " 'volatilidade_3m': 'vol3', 'vol3': 'vol3',\n",
    " 'volatilidade_6m': 'vol6', 'vol6': 'vol6',\n",
    " 'momentum': 'momentum3', 'momentum3': 'momentum3',\n",
    " 'volume_relativo': 'volrel', 'volrel': 'volrel',\n",
    " 'close_plus1': 'close_plus1', 'close_+1': 'close_plus1'\n",
    "}\n",
    "df = df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns})\n",
    "df['date'] = pd.to_datetime(df['date'], dayfirst=True, errors='coerce')\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "# Conversão numérica das colunas\n",
    "num_cols = ['close','ret_m','mm3','mm6','mm12','vol3','vol6',\n",
    "           'momentum3','volrel','close_plus1']\n",
    "for c in num_cols:\n",
    " if c in df.columns:\n",
    "     df[c] = (df[c].astype(str)\n",
    "                     .str.replace('\\u00A0','',regex=False)\n",
    "                     .str.replace('%','',regex=False)\n",
    "                     .str.replace(' ','',regex=False))\n",
    "     df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "# =========================================================\n",
    "# 4) TRATAMENTO CASO close_plus1 NÃO EXISTA\n",
    "# =========================================================\n",
    "if 'close_plus1' not in df.columns:\n",
    " df['close_plus1'] = df['close'].shift(-1)\n",
    "# =========================================================\n",
    "# 5) SEPARAR HISTÓRICO (até 2023-12) e REAIS DE 2024 (se houver)\n",
    "# =========================================================\n",
    "limite_hist = pd.Timestamp('2023-12-01')\n",
    "df_hist = df[df['date'] <= limite_hist].copy()\n",
    "df_2024 = df[(df['date'] >= pd.Timestamp('2024-01-01')) &\n",
    "           (df['date'] <= pd.Timestamp('2024-12-31'))][['date','close']].copy()\n",
    "df_2024.rename(columns={'close':'close_real'}, inplace=True)\n",
    "if 'close_plus1' in df_hist.columns:\n",
    " assert pd.isna(df_hist.loc[len(df_hist)-1, 'close_plus1']), \\\n",
    "     \"A última linha de 2023 deve estar vazia em close_plus1 (alvo desconhecido).\"\n",
    "print(\"Linhas histórico (<=2023-12):\", len(df_hist))\n",
    "print(\"Linhas 2024 (se houver no CSV):\", len(df_2024))\n",
    "# =========================================================\n",
    "# 6) TREINO (Random Forest) COM VALIDAÇÃO TEMPORAL\n",
    "# =========================================================\n",
    "FEATS = ['ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel']\n",
    "TARGET = 'close_plus1'\n",
    "train = df_hist.dropna(subset=FEATS + [TARGET]).copy()\n",
    "print(\"Linhas após dropna (treino):\", len(train))\n",
    "assert len(train) >= 12, \"Poucos dados após limpeza (verifique NaNs).\"\n",
    "X = train[FEATS].values\n",
    "y = train[TARGET].values\n",
    "forest = RandomForestRegressor(random_state=42)\n",
    "grid = {\n",
    "  'n_estimators': [100, 200],\n",
    "  'max_depth': [3, 5, 7, 9],\n",
    "  'min_samples_split': [2, 3, 4],\n",
    "  'min_samples_leaf': [1, 2]\n",
    "}\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "g = GridSearchCV(forest, grid, cv=tscv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "g.fit(X, y)\n",
    "best_forest = g.best_estimator_\n",
    "# =========================================================\n",
    "# 7) OUT-OF-FOLD MÉTRICAS (HISTÓRICO)\n",
    "# =========================================================\n",
    "y_oof = np.full_like(y, np.nan, dtype=float)\n",
    "for tr, te in tscv.split(X):\n",
    " best_forest.fit(X[tr], y[tr])\n",
    " y_oof[te] = best_forest.predict(X[te])\n",
    "mask = ~np.isnan(y_oof)\n",
    "mae  = mean_absolute_error(y[mask], y_oof[mask])\n",
    "mse  = mean_squared_error(y[mask], y_oof[mask])\n",
    "rmse = np.sqrt(mse)\n",
    "r2   = r2_score(y[mask], y_oof[mask])\n",
    "print(f\"\\nRandomForest | MAE={mae:.3f} RMSE={rmse:.3f} R²={r2:.3f} best={g.best_params_}\")\n",
    "# =========================================================\n",
    "# 8) REFIT NO HISTÓRICO COMPLETO\n",
    "# =========================================================\n",
    "best_forest.fit(X, y)\n",
    "# =========================================================\n",
    "# 9) PROJEÇÃO RECURSIVA DE 12 MESES (2024)\n",
    "# =========================================================\n",
    "def roll_mean(a,n): return np.mean(a[-n:]) if len(a)>=n else np.nan\n",
    "def roll_std(a,n):  return np.std(a[-n:], ddof=1) if len(a)>=n else np.nan\n",
    "work = df_hist[['date','close','ret_m','mm3','mm6','mm12',\n",
    "              'vol3','vol6','momentum3','volrel']].copy()\n",
    "volrel_last3 = work['volrel'].tail(3).mean()\n",
    "last_close   = work['close'].iloc[-1]\n",
    "rows = []\n",
    "alvos_2024 = pd.date_range('2024-01-01', '2024-12-01', freq='MS')\n",
    "for next_date in alvos_2024:\n",
    " feats_now = work.iloc[-1][FEATS].to_dict()\n",
    " feats_now['volrel'] = volrel_last3\n",
    " x = np.array([feats_now[f] for f in FEATS], dtype=float).reshape(1, -1)\n",
    " pred_close_next = float(best_forest.predict(x)[0])\n",
    " ret_next = (pred_close_next / last_close) - 1.0\n",
    " work = pd.concat([work, pd.DataFrame([{\n",
    "     'date': next_date,\n",
    "     'close': pred_close_next,\n",
    "     'ret_m': ret_next,\n",
    "     'volrel': volrel_last3\n",
    " }])], ignore_index=True)\n",
    " closes = work['close'].values\n",
    " rets   = work['ret_m'].values\n",
    " work.loc[work.index[-1], 'mm3']  = roll_mean(closes, 3)\n",
    " work.loc[work.index[-1], 'mm6']  = roll_mean(closes, 6)\n",
    " work.loc[work.index[-1], 'mm12'] = roll_mean(closes, 12)\n",
    " work.loc[work.index[-1], 'vol3'] = roll_std(rets, 3)\n",
    " work.loc[work.index[-1], 'vol6'] = roll_std(rets, 6)\n",
    " if len(closes) >= 4:\n",
    "     work.loc[work.index[-1], 'momentum3'] = (closes[-1]/closes[-4]) - 1\n",
    " last_close = pred_close_next\n",
    " rows.append({'date': next_date, 'close_pred': pred_close_next})\n",
    "pred_2024 = pd.DataFrame(rows).sort_values('date').reset_index(drop=True)\n",
    "# =========================================================\n",
    "# 10) AVALIAÇÃO CONTRA REAIS DE 2024 (SE EXISTIREM)\n",
    "# =========================================================\n",
    "avaliacao_2024 = None\n",
    "if len(df_2024) > 0:\n",
    " avaliacao_2024 = pred_2024.merge(df_2024, on='date', how='left')\n",
    " if 'close_real' in avaliacao_2024.columns and avaliacao_2024['close_real'].notna().any():\n",
    "     avaliacao_2024['erro_abs'] = (avaliacao_2024['close_pred'] - avaliacao_2024['close_real']).abs()\n",
    "     avaliacao_2024['erro_%']   = (avaliacao_2024['close_pred'] / avaliacao_2024['close_real'] - 1.0) * 100\n",
    "     mae_24  = avaliacao_2024['erro_abs'].mean(skipna=True)\n",
    "     rmse_24 = np.sqrt(((avaliacao_2024['close_pred'] - avaliacao_2024['close_real'])**2).mean(skipna=True))\n",
    "     print(f\"\\n(Comparação holdout 2024) MAE={mae_24:.3f} RMSE={rmse_24:.3f}\")\n",
    " else:\n",
    "     print(\"\\nSem closes reais de 2024 no CSV; apenas previsões foram geradas.\")\n",
    "# =========================================================\n",
    "# 11) SALVAR RESULTADOS NO EXCEL\n",
    "# =========================================================\n",
    "try:\n",
    " with pd.ExcelWriter(OUTPUT_PATH, engine='xlsxwriter') as w:\n",
    "     pred_2024.to_excel(w, index=False, sheet_name='predicoes_2024')\n",
    "     pd.DataFrame([{'MAE_hist': mae, 'RMSE_hist': rmse, 'R2_hist': r2, **g.best_params_}]).to_excel(\n",
    "         w, index=False, sheet_name='metricas_hist')\n",
    "     if avaliacao_2024 is not None:\n",
    "         avaliacao_2024.to_excel(w, index=False, sheet_name='avaliacao_2024')\n",
    "except Exception:\n",
    " with pd.ExcelWriter(OUTPUT_PATH, engine='openpyxl') as w:\n",
    "     pred_2024.to_excel(w, index=False, sheet_name='predicoes_2024')\n",
    "     pd.DataFrame([{'MAE_hist': mae, 'RMSE_hist': rmse, 'R2_hist': r2, **g.best_params_}]).to_excel(\n",
    "         w, index=False, sheet_name='metricas_hist')\n",
    "     if avaliacao_2024 is not None:\n",
    "         avaliacao_2024.to_excel(w, index=False, sheet_name='avaliacao_2024')\n",
    "print(f\"\\n✅ Arquivo gerado com sucesso em:\\n{OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeb73c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
