{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59d8430c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linhas histórico (<=2023-12): 48\n",
      "Linhas 2024 no CSV (se houver): 0\n",
      "Linhas após dropna (treino): 47\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 83>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     75\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     76\u001b[0m    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m400\u001b[39m, \u001b[38;5;241m700\u001b[39m, \u001b[38;5;241m1000\u001b[39m],\n\u001b[0;32m     77\u001b[0m    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_features\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msqrt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m     81\u001b[0m }\n\u001b[0;32m     82\u001b[0m g \u001b[38;5;241m=\u001b[39m GridSearchCV(rf, param_grid, cv\u001b[38;5;241m=\u001b[39mtscv, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_absolute_error\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 83\u001b[0m \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m best_rf \u001b[38;5;241m=\u001b[39m g\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# =========================================================\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# 6) MÉTRICAS OOF (HISTÓRICO) + REFIT COMPLETO\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# =========================================================\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1020\u001b[0m     )\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1570\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1571\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    967\u001b[0m         )\n\u001b[0;32m    968\u001b[0m     )\n\u001b[1;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\parallel.py:2072\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2066\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2067\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2068\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2070\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\parallel.py:1682\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1679\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1681\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1682\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1685\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\parallel.py:1800\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_ordered:\n\u001b[0;32m   1790\u001b[0m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[0;32m   1791\u001b[0m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1795\u001b[0m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[0;32m   1796\u001b[0m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[0;32m   1797\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1798\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING\n\u001b[0;32m   1799\u001b[0m     ):\n\u001b[1;32m-> 1800\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1801\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1803\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1804\u001b[0m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[0;32m   1805\u001b[0m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1811\u001b[0m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[0;32m   1812\u001b[0m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# 1) IMPORTS\n",
    "# =========================================================\n",
    "import os\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "# =========================================================\n",
    "# 2) CAMINHOS / LEITURA\n",
    "# =========================================================\n",
    "INPUT_PATH = r\"C:\\Users\\kinagaki\\OneDrive - Digicorner\\Desktop\\Trabalho de Conclusão de Curso - UFRJ.2025\\Correção\\versão atualizada\\TESTE BOVA 11\\bova11_ate_2023.csv\"\n",
    "BASE_DIR = os.path.dirname(INPUT_PATH)\n",
    "OUTPUT_PATH = os.path.join(BASE_DIR, \"bova11_pred_2024_rf.xlsx\")\n",
    "df = pd.read_csv(INPUT_PATH, sep=\";\", decimal=\",\", thousands=\".\")\n",
    "# =========================================================\n",
    "# 3) PADRONIZAÇÃO DE COLUNAS / TIPOS\n",
    "# =========================================================\n",
    "df.columns = (df.columns\n",
    "   .str.strip()\n",
    "   .str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "   .str.lower()\n",
    ")\n",
    "rename_map = {\n",
    "   'data': 'date',\n",
    "   'ultimo': 'close', 'último': 'close',\n",
    "   'retorno_mensal_(%)': 'ret_m', 'retorno_mensal': 'ret_m',\n",
    "   'média_móvel_3m': 'mm3', 'media_movel_3m': 'mm3',\n",
    "   'média_móvel_6m': 'mm6', 'media_movel_6m': 'mm6',\n",
    "   'média_móvel_12m': 'mm12','media_movel_12m': 'mm12',\n",
    "   'volatilidade_3m': 'vol3', 'vol3': 'vol3',\n",
    "   'volatilidade_6m': 'vol6', 'vol6': 'vol6',\n",
    "   'momentum': 'momentum3', 'momentum3': 'momentum3',\n",
    "   'volume_relativo': 'volrel', 'volrel': 'volrel',\n",
    "   'close_plus1': 'close_plus1', 'close_+1': 'close_plus1'\n",
    "}\n",
    "df = df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns})\n",
    "df['date'] = pd.to_datetime(df['date'], dayfirst=True, errors='coerce')\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "num_cols = ['close','ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel','close_plus1']\n",
    "for c in num_cols:\n",
    "   if c in df.columns:\n",
    "       df[c] = (df[c].astype(str)\n",
    "                       .str.replace('\\u00A0','',regex=False)\n",
    "                       .str.replace('%','',regex=False)\n",
    "                       .str.replace(' ','',regex=False))\n",
    "       df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "# Se não houver close_plus1, cria via shift(-1)\n",
    "if 'close_plus1' not in df.columns:\n",
    "   df['close_plus1'] = df['close'].shift(-1)\n",
    "# =========================================================\n",
    "# 4) HISTÓRICO (<= 2023-12) E REAIS 2024 (OPCIONAL)\n",
    "# =========================================================\n",
    "limite_hist = pd.Timestamp('2023-12-01')\n",
    "df_hist = df[df['date'] <= limite_hist].copy()\n",
    "df_2024 = df[(df['date'] >= '2024-01-01') & (df['date'] <= '2024-12-31')][['date','close']].copy()\n",
    "df_2024.rename(columns={'close':'close_real'}, inplace=True)\n",
    "if 'close_plus1' in df_hist.columns:\n",
    "   assert pd.isna(df_hist.loc[len(df_hist)-1, 'close_plus1']), \\\n",
    "       \"A última linha de 2023 deve estar vazia em close_plus1 (alvo desconhecido).\"\n",
    "print(\"Linhas histórico (<=2023-12):\", len(df_hist))\n",
    "print(\"Linhas 2024 no CSV (se houver):\", len(df_2024))\n",
    "# =========================================================\n",
    "# 5) TREINO: RANDOM FOREST + TSCV + GRIDSEARCH\n",
    "# =========================================================\n",
    "FEATS  = ['ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel']\n",
    "TARGET = 'close_plus1'\n",
    "train = df_hist.dropna(subset=FEATS + [TARGET]).copy()\n",
    "print(\"Linhas após dropna (treino):\", len(train))\n",
    "assert len(train) >= 12, \"Poucos dados após limpeza.\"\n",
    "X = train[FEATS].values\n",
    "y = train[TARGET].values\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "param_grid = {\n",
    "   'n_estimators': [400, 700, 1000],\n",
    "   'max_depth': [3, 4, 5, 6],\n",
    "   'min_samples_leaf': [2, 3, 4, 5],\n",
    "   'min_samples_split': [2, 4, 6],\n",
    "   'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "g = GridSearchCV(rf, param_grid, cv=tscv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "g.fit(X, y)\n",
    "best_rf = g.best_estimator_\n",
    "# =========================================================\n",
    "# 6) MÉTRICAS OOF (HISTÓRICO) + REFIT COMPLETO\n",
    "# =========================================================\n",
    "y_oof = np.full_like(y, np.nan, dtype=float)\n",
    "for tr, te in tscv.split(X):\n",
    "   best_rf.fit(X[tr], y[tr])\n",
    "   y_oof[te] = best_rf.predict(X[te])\n",
    "mask = ~np.isnan(y_oof)\n",
    "mae  = mean_absolute_error(y[mask], y_oof[mask])\n",
    "mse  = mean_squared_error(y[mask], y_oof[mask])\n",
    "rmse = np.sqrt(mse)\n",
    "r2   = r2_score(y[mask], y_oof[mask])\n",
    "print(f\"\\nRandomForest | (Histórico 2020–2023) MAE={mae:.3f} RMSE={rmse:.3f} R²={r2:.3f} best={g.best_params_}\")\n",
    "# Refit em 100% do histórico (para projetar 2024)\n",
    "best_rf.fit(X, y)\n",
    "# =========================================================\n",
    "# 7) PROJEÇÃO RECURSIVA: 12 MESES DE 2024\n",
    "# =========================================================\n",
    "def roll_mean(a,n): return np.mean(a[-n:]) if len(a)>=n else np.nan\n",
    "def roll_std(a,n):  return np.std(a[-n:], ddof=1) if len(a)>=n else np.nan\n",
    "work = df_hist[['date','close','ret_m','mm3','mm6','mm12','vol3','vol6','momentum3','volrel']].copy()\n",
    "volrel_last3 = work['volrel'].tail(3).mean()\n",
    "last_close   = work['close'].iloc[-1]\n",
    "rows = []\n",
    "alvos_2024 = pd.date_range('2024-01-01', '2024-12-01', freq='MS')\n",
    "for next_date in alvos_2024:\n",
    "   feats_now = work.iloc[-1][FEATS].to_dict()\n",
    "   feats_now['volrel'] = volrel_last3\n",
    "   x = np.array([feats_now[f] for f in FEATS], dtype=float).reshape(1, -1)\n",
    "   pred_close_next = float(best_rf.predict(x)[0])\n",
    "   ret_next  = (pred_close_next / last_close) - 1.0\n",
    "   work = pd.concat([work, pd.DataFrame([{\n",
    "       'date': next_date,\n",
    "       'close': pred_close_next,\n",
    "       'ret_m': ret_next,\n",
    "       'volrel': volrel_last3\n",
    "   }])], ignore_index=True)\n",
    "   closes = work['close'].values\n",
    "   rets   = work['ret_m'].values\n",
    "   work.loc[work.index[-1], 'mm3']  = roll_mean(closes, 3)\n",
    "   work.loc[work.index[-1], 'mm6']  = roll_mean(closes, 6)\n",
    "   work.loc[work.index[-1], 'mm12'] = roll_mean(closes, 12)\n",
    "   work.loc[work.index[-1], 'vol3'] = roll_std(rets, 3)\n",
    "   work.loc[work.index[-1], 'vol6'] = roll_std(rets, 6)\n",
    "   if len(closes) >= 4:\n",
    "       work.loc[work.index[-1], 'momentum3'] = (closes[-1]/closes[-4]) - 1\n",
    "   last_close = pred_close_next\n",
    "   rows.append({'date': next_date, 'close_pred': pred_close_next})\n",
    "pred_2024 = pd.DataFrame(rows).sort_values('date').reset_index(drop=True)\n",
    "# =========================================================\n",
    "# 8) AVALIAÇÃO CONTRA REAIS DE 2024 (OPCIONAL)\n",
    "# =========================================================\n",
    "avaliacao_2024 = None\n",
    "if len(df_2024) > 0:\n",
    "   avaliacao_2024 = pred_2024.merge(df_2024, on='date', how='left')\n",
    "   if 'close_real' in avaliacao_2024.columns and avaliacao_2024['close_real'].notna().any():\n",
    "       avaliacao_2024['erro_abs'] = (avaliacao_2024['close_pred'] - avaliacao_2024['close_real']).abs()\n",
    "       avaliacao_2024['erro_%']   = (avaliacao_2024['close_pred'] / avaliacao_2024['close_real'] - 1.0) * 100\n",
    "       mae_24  = avaliacao_2024['erro_abs'].mean(skipna=True)\n",
    "       rmse_24 = np.sqrt(((avaliacao_2024['close_pred'] - avaliacao_2024['close_real'])**2).mean(skipna=True))\n",
    "       print(f\"\\n(Comparação holdout 2024) MAE={mae_24:.3f} RMSE={rmse_24:.3f}\")\n",
    "   else:\n",
    "       print(\"\\nSem closes reais de 2024 no CSV; apenas previsões foram geradas.\")\n",
    "# =========================================================\n",
    "# 9) IMPORTÂNCIAS DAS VARIÁVEIS\n",
    "# =========================================================\n",
    "imp = pd.DataFrame({\n",
    "   'variavel': FEATS,\n",
    "   'importancia': best_rf.feature_importances_\n",
    "}).sort_values('importancia', ascending=False)\n",
    "imp['importancia_%'] = 100 * imp['importancia'] / imp['importancia'].sum()\n",
    "# =========================================================\n",
    "# 10) SALVAR RESULTADOS NO EXCEL\n",
    "# =========================================================\n",
    "try:\n",
    "   with pd.ExcelWriter(OUTPUT_PATH, engine='xlsxwriter') as w:\n",
    "       pred_2024.to_excel(w, index=False, sheet_name='predicoes_2024')\n",
    "       pd.DataFrame([{'MAE_hist': mae, 'RMSE_hist': rmse, 'R2_hist': r2, **g.best_params_}]).to_excel(\n",
    "           w, index=False, sheet_name='metricas_hist')\n",
    "       imp.to_excel(w, index=False, sheet_name='importancias_rf')\n",
    "       if avaliacao_2024 is not None:\n",
    "           avaliacao_2024.to_excel(w, index=False, sheet_name='avaliacao_2024')\n",
    "except Exception:\n",
    "   with pd.ExcelWriter(OUTPUT_PATH, engine='openpyxl') as w:\n",
    "       pred_2024.to_excel(w, index=False, sheet_name='predicoes_2024')\n",
    "       pd.DataFrame([{'MAE_hist': mae, 'RMSE_hist': rmse, 'R2_hist': r2, **g.best_params_}]).to_excel(\n",
    "           w, index=False, sheet_name='metricas_hist')\n",
    "       imp.to_excel(w, index=False, sheet_name='importancias_rf')\n",
    "       if avaliacao_2024 is not None:\n",
    "           avaliacao_2024.to_excel(w, index=False, sheet_name='avaliacao_2024')\n",
    "print(f\"\\n✅ Arquivo gerado com sucesso em:\\n{OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4bd429b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linhas histórico (<=2023-12): 48\n",
      "Linhas 2024 (se houver no CSV): 0\n",
      "Linhas após dropna (treino): 47\n",
      "\n",
      "RandomForest | MAE=5.213 RMSE=6.929 R²=0.033 best={'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "\n",
      "✅ Arquivo gerado com sucesso em:\n",
      "C:\\Users\\kinagaki\\OneDrive - Digicorner\\Desktop\\Trabalho de Conclusão de Curso - UFRJ.2025\\Correção\\versão atualizada\\TESTE BOVA 11\\bova11_pred_2024_forest.xlsx\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# 1) IMPORTS\n",
    "# =========================================================\n",
    "import os\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "# =========================================================\n",
    "# 2) CAMINHOS / LEITURA\n",
    "# =========================================================\n",
    "INPUT_PATH = r\"C:\\Users\\kinagaki\\OneDrive - Digicorner\\Desktop\\Trabalho de Conclusão de Curso - UFRJ.2025\\Correção\\versão atualizada\\TESTE BOVA 11\\bova11_ate_2023.csv\"\n",
    "BASE_DIR = os.path.dirname(INPUT_PATH)\n",
    "OUTPUT_PATH = os.path.join(BASE_DIR, \"bova11_pred_2024_forest.xlsx\")\n",
    "df = pd.read_csv(INPUT_PATH, sep=\";\", decimal=\",\", thousands=\".\")\n",
    "# =========================================================\n",
    "# 3) PADRONIZAÇÃO DE COLUNAS / TIPOS\n",
    "# =========================================================\n",
    "df.columns = (df.columns\n",
    "  .str.strip()\n",
    "  .str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "  .str.lower()\n",
    ")\n",
    "rename_map = {\n",
    "  'data': 'date',\n",
    "  'ultimo': 'close', 'último': 'close',\n",
    "  'retorno_mensal_(%)': 'ret_m', 'retorno_mensal': 'ret_m',\n",
    "  'média_móvel_3m': 'mm3', 'media_movel_3m': 'mm3',\n",
    "  'média_móvel_6m': 'mm6', 'media_movel_6m': 'mm6',\n",
    "  'média_móvel_12m': 'mm12','media_movel_12m': 'mm12',\n",
    "  'volatilidade_3m': 'vol3', 'vol3': 'vol3',\n",
    "  'volatilidade_6m': 'vol6', 'vol6': 'vol6',\n",
    "  'momentum': 'momentum3', 'momentum3': 'momentum3',\n",
    "  'volume_relativo': 'volrel', 'volrel': 'volrel',\n",
    "  'close_plus1': 'close_plus1', 'close_+1': 'close_plus1'\n",
    "}\n",
    "df = df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns})\n",
    "df['date'] = pd.to_datetime(df['date'], dayfirst=True, errors='coerce')\n",
    "df = df.sort_values('date').reset_index(drop=True)\n",
    "# Conversão numérica das colunas\n",
    "num_cols = [\n",
    "   'close','ret_m','mm3','mm6','mm12','vol3','vol6',\n",
    "   'momentum3','volrel','close_plus1','selic_m','ipca_m'\n",
    "]\n",
    "for c in num_cols:\n",
    "  if c in df.columns:\n",
    "      df[c] = (df[c].astype(str)\n",
    "                      .str.replace('\\u00A0','',regex=False)\n",
    "                      .str.replace('%','',regex=False)\n",
    "                      .str.replace(' ','',regex=False))\n",
    "      df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "# =========================================================\n",
    "# 4) TRATAMENTO CASO close_plus1 NÃO EXISTA\n",
    "# =========================================================\n",
    "if 'close_plus1' not in df.columns:\n",
    "  df['close_plus1'] = df['close'].shift(-1)\n",
    "# =========================================================\n",
    "# 5) SEPARAR HISTÓRICO (até 2023-12) e REAIS DE 2024 (se houver)\n",
    "# =========================================================\n",
    "limite_hist = pd.Timestamp('2023-12-01')\n",
    "df_hist = df[df['date'] <= limite_hist].copy()\n",
    "df_2024 = df[(df['date'] >= pd.Timestamp('2024-01-01')) &\n",
    "            (df['date'] <= pd.Timestamp('2024-12-31'))][['date','close']].copy()\n",
    "df_2024.rename(columns={'close':'close_real'}, inplace=True)\n",
    "if 'close_plus1' in df_hist.columns:\n",
    "  assert pd.isna(df_hist.loc[len(df_hist)-1, 'close_plus1']), \\\n",
    "      \"A última linha de 2023 deve estar vazia em close_plus1 (alvo desconhecido).\"\n",
    "print(\"Linhas histórico (<=2023-12):\", len(df_hist))\n",
    "print(\"Linhas 2024 (se houver no CSV):\", len(df_2024))\n",
    "# =========================================================\n",
    "# 6) TREINO (Random Forest) COM VALIDAÇÃO TEMPORAL\n",
    "# =========================================================\n",
    "FEATS = ['ret_m','mm3','mm6','mm12','vol3','vol6',\n",
    "        'momentum3','volrel','selic_m','ipca_m']\n",
    "TARGET = 'close_plus1'\n",
    "train = df_hist.dropna(subset=FEATS + [TARGET]).copy()\n",
    "print(\"Linhas após dropna (treino):\", len(train))\n",
    "assert len(train) >= 12, \"Poucos dados após limpeza (verifique NaNs).\"\n",
    "X = train[FEATS].values\n",
    "y = train[TARGET].values\n",
    "# Define o modelo e o grid de parâmetros\n",
    "forest = RandomForestRegressor(random_state=42)\n",
    "grid = {\n",
    "   'n_estimators': [100, 200],\n",
    "   'max_depth': [3, 5, 7, 9],\n",
    "   'min_samples_split': [2, 3, 4],\n",
    "   'min_samples_leaf': [1, 2]\n",
    "}\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "g = GridSearchCV(forest, grid, cv=tscv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "g.fit(X, y)\n",
    "best_forest = g.best_estimator_\n",
    "# =========================================================\n",
    "# 7) OUT-OF-FOLD MÉTRICAS (HISTÓRICO)\n",
    "# =========================================================\n",
    "y_oof = np.full_like(y, np.nan, dtype=float)\n",
    "for tr, te in tscv.split(X):\n",
    "  best_forest.fit(X[tr], y[tr])\n",
    "  y_oof[te] = best_forest.predict(X[te])\n",
    "mask = ~np.isnan(y_oof)\n",
    "mae  = mean_absolute_error(y[mask], y_oof[mask])\n",
    "mse  = mean_squared_error(y[mask], y_oof[mask])\n",
    "rmse = np.sqrt(mse)\n",
    "r2   = r2_score(y[mask], y_oof[mask])\n",
    "print(f\"\\nRandomForest | MAE={mae:.3f} RMSE={rmse:.3f} R²={r2:.3f} best={g.best_params_}\")\n",
    "# =========================================================\n",
    "# 8) REFIT NO HISTÓRICO COMPLETO\n",
    "# =========================================================\n",
    "best_forest.fit(X, y)\n",
    "# =========================================================\n",
    "# 9) PROJEÇÃO RECURSIVA DE 12 MESES (2024)\n",
    "# =========================================================\n",
    "def roll_mean(a,n): return np.mean(a[-n:]) if len(a)>=n else np.nan\n",
    "def roll_std(a,n):  return np.std(a[-n:], ddof=1) if len(a)>=n else np.nan\n",
    "selic_last = df_hist['selic_m'].dropna().iloc[-1] if 'selic_m' in df_hist.columns else np.nan\n",
    "ipca_last  = df_hist['ipca_m'].dropna().iloc[-1]  if 'ipca_m'  in df_hist.columns else np.nan\n",
    "work = df_hist[['date','close','ret_m','mm3','mm6','mm12','vol3','vol6',\n",
    "               'momentum3','volrel','selic_m','ipca_m']].copy()\n",
    "volrel_last3 = work['volrel'].tail(3).mean()\n",
    "last_close   = work['close'].iloc[-1]\n",
    "rows = []\n",
    "alvos_2024 = pd.date_range('2024-01-01', '2024-12-01', freq='MS')\n",
    "for next_date in alvos_2024:\n",
    "  feats_now = work.iloc[-1][FEATS].to_dict()\n",
    "  feats_now['selic_m'] = selic_last\n",
    "  feats_now['ipca_m']  = ipca_last\n",
    "  feats_now['volrel']  = volrel_last3\n",
    "  x = np.array([feats_now[f] for f in FEATS], dtype=float).reshape(1, -1)\n",
    "  pred_close_next = float(best_forest.predict(x)[0])\n",
    "  ret_next = (pred_close_next / last_close) - 1.0\n",
    "  work = pd.concat([work, pd.DataFrame([{\n",
    "      'date': next_date,\n",
    "      'close': pred_close_next,\n",
    "      'ret_m': ret_next,\n",
    "      'volrel': volrel_last3,\n",
    "      'selic_m': selic_last,\n",
    "      'ipca_m': ipca_last\n",
    "  }])], ignore_index=True)\n",
    "  closes = work['close'].values\n",
    "  rets   = work['ret_m'].values\n",
    "  work.loc[work.index[-1], 'mm3']  = roll_mean(closes, 3)\n",
    "  work.loc[work.index[-1], 'mm6']  = roll_mean(closes, 6)\n",
    "  work.loc[work.index[-1], 'mm12'] = roll_mean(closes, 12)\n",
    "  work.loc[work.index[-1], 'vol3'] = roll_std(rets, 3)\n",
    "  work.loc[work.index[-1], 'vol6'] = roll_std(rets, 6)\n",
    "  if len(closes) >= 4:\n",
    "      work.loc[work.index[-1], 'momentum3'] = (closes[-1]/closes[-4]) - 1\n",
    "  last_close = pred_close_next\n",
    "  rows.append({'date': next_date, 'close_pred': pred_close_next})\n",
    "pred_2024 = pd.DataFrame(rows).sort_values('date').reset_index(drop=True)\n",
    "# =========================================================\n",
    "# 10) AVALIAÇÃO CONTRA REAIS DE 2024 (SE EXISTIREM)\n",
    "# =========================================================\n",
    "avaliacao_2024 = None\n",
    "if len(df_2024) > 0:\n",
    "  avaliacao_2024 = pred_2024.merge(df_2024, on='date', how='left')\n",
    "  if 'close_real' in avaliacao_2024.columns and avaliacao_2024['close_real'].notna().any():\n",
    "      avaliacao_2024['erro_abs'] = (avaliacao_2024['close_pred'] - avaliacao_2024['close_real']).abs()\n",
    "      avaliacao_2024['erro_%']   = (avaliacao_2024['close_pred'] / avaliacao_2024['close_real'] - 1.0) * 100\n",
    "      mae_24  = avaliacao_2024['erro_abs'].mean(skipna=True)\n",
    "      rmse_24 = np.sqrt(((avaliacao_2024['close_pred'] - avaliacao_2024['close_real'])**2).mean(skipna=True))\n",
    "      print(f\"\\n(Comparação holdout 2024) MAE={mae_24:.3f} RMSE={rmse_24:.3f}\")\n",
    "  else:\n",
    "      print(\"\\nSem closes reais de 2024 no CSV; apenas previsões foram geradas.\")\n",
    "# =========================================================\n",
    "# 11) SALVAR RESULTADOS NO EXCEL\n",
    "# =========================================================\n",
    "try:\n",
    "  with pd.ExcelWriter(OUTPUT_PATH, engine='xlsxwriter') as w:\n",
    "      pred_2024.to_excel(w, index=False, sheet_name='predicoes_2024')\n",
    "      pd.DataFrame([{'MAE_hist': mae, 'RMSE_hist': rmse, 'R2_hist': r2, **g.best_params_}]).to_excel(\n",
    "          w, index=False, sheet_name='metricas_hist')\n",
    "      if avaliacao_2024 is not None:\n",
    "          avaliacao_2024.to_excel(w, index=False, sheet_name='avaliacao_2024')\n",
    "except Exception:\n",
    "  with pd.ExcelWriter(OUTPUT_PATH, engine='openpyxl') as w:\n",
    "      pred_2024.to_excel(w, index=False, sheet_name='predicoes_2024')\n",
    "      pd.DataFrame([{'MAE_hist': mae, 'RMSE_hist': rmse, 'R2_hist': r2, **g.best_params_}]).to_excel(\n",
    "          w, index=False, sheet_name='metricas_hist')\n",
    "      if avaliacao_2024 is not None:\n",
    "          avaliacao_2024.to_excel(w, index=False, sheet_name='avaliacao_2024')\n",
    "print(f\"\\n✅ Arquivo gerado com sucesso em:\\n{OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcd715d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
